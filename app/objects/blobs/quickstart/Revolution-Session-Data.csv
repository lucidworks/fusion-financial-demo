year,location,speaker_name,organization,speaker_bio,title,track,summary,youtube_url,slideshare_url
2017,"Las Vegas, NV",Alexander Kanarsky,Lucidworks,,Introduction to Lucidworks Fusion,Solr for Business,"Build better search apps with Lucidworks Fusion, a scalable development platform leveraging the power of Apache Solr and Spark. Fusion provides everything you need to build and deploy intelligent search applications, from data acquisition tools and built-in security, to advanced signals and ML models processing for relevance tuning. FusionÃ•s paradigm of data pipelines on both the indexing and query sides allows for rapid application development and configuration. Fusion ships with search analytics tools, custom user interface components, data visualization tools, cloud deployment support, and many other mission critical features, meaning faster time to market for your search and data applications.",https://youtu.be/ZxJexna4qXQ,https://www.slideshare.net/lucidworks/introduction-to-lucidworks-fusion-alexander-kanarsky-lucidworks
2017,"Las Vegas, NV",Trey Grainger,Lucidworks,,The Apache Solr Semantic Knowledge Graph,Solr & Machine Learning ,"What if instead of a query returning documents, you could alternatively return other keywords most related to the query: i.e. given a search for ""data science"", return me back results like ""machine learning"", ""predictive modeling"", ""artificial neural networks"", etc.? SolrÃ•s Semantic Knowledge Graph does just that. It leverages the inverted index to automatically model the significance of relationships between every term in the inverted index (even across multiple fields) allowing real-time traversal and ranking of any relationship within your documents. Use cases for the Semantic Knowledge Graph include disambiguation of multiple meanings of terms (does ""driver"" mean truck driver, printer driver, a type of golf club, etc.), searching on vectors of related keywords to form a conceptual search (versus just a text match), powering recommendation algorithms, ranking lists of keywords based upon conceptual cohesion to reduce noise, summarizing documents by extracting their most significant terms, and numerous other applications involving anomaly detection, significance/relationship discovery, and semantic search. In this talk, we'll do a deep dive into the internals of how the Semantic Knowledge Graph works and will walk you through how to get up and running with an example dataset to explore the meaningful relationships hidden within your data.",https://youtu.be/JvuQX92zyi0,
2017,"Las Vegas, NV",Shalin Shekhar Mangar,Lucidworks,,Autoscaling Solr,,"A large body of work is underway to build autoscaling into Solr with the goal of improving cluster stability and performance as well as to make cluster management simpler and easier for Solr users. The first release of autoscaling features should happen starting with Solr 7. We will go through the various features that help you setup autoscaling for your Solr clusters whether in the cloud or in-house so that: 1. The cluster can show notifications or raise alarms on important cluster events such as a node joining the cluster or leaving the cluster2. Newly added nodes automatically start sharing the traffic and reduce overall system load across the cluster3. The indexes hosted on nodes that either die or are decommissioned is automatically shifted to other nodes in the cluster4. The cluster automatically attempts to reduce average system load or tries to optimize around administrator defined criteriaWe shall also discuss the internal design and relevant implementation details as well as the pluggable components around these features so that interested users can customize and extend the autoscaling features as per their own needs.",https://youtu.be/bI5z4fWome4,https://www.slideshare.net/lucidworks/autoscaling-solr-shalin-shekhar-mangar-lucidworks
2017,"Las Vegas, NV",Noble Paul,Lucidworks,,What's New in Solr 7,Lightning Talk,An overview of the new capabilities in Solr 7,https://youtu.be/JvuQX92zyi0,
2017,"Las Vegas, NV",Jacob Mannix,Lucidworks,,Vector Embeddings for Solr,Solr & Machine Learning ,"In this session, we will go over various ways nonlinear vector embeddings can be used for search:    * Word2Vec and GloVe learn a ""conceptual"" vector space of lower dimension than the input vocabulary, and as such can be used in IR in similar ways to other dimensional reduction techniques such as LSI, pLSI, and LDA.   * Doc2Vec can learn better vectors for documents larger than a single sentence, and can also learn supervised class labels at the same time, to create a classifier for both documents and queries   * Shallow neural net-based embeddings trained on click data as a supervisory signal can learn a joint model over queries and document snippets to perform learning to rank.  We will demonstrate how to train all three of these models with open source tools and integrate them with a Solr-based search engine.",https://youtu.be/IwLK2A4eFIs,
2017,"Las Vegas, NV",Andrew Thanalertvisuti,Lucidworks,,Apache Zeppelin Solr Interpreter,Solr & Machine Learning,"Apache Zeppelin is a web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala and more. With the Solr interpreter, Zeppelin can now utilize Solr as backend and allow users to issue Solr queires to visualize results in the Zeppelin UI. Currently, Solr interpreter supports basic Solr search, SQL, and Streaming expression queries. More capabilities are being developed and will be added soon. In this talk, we will walk you through how to get up and running with an example dataset to see various commands that we can use with Solr interpreter.",https://youtu.be/AWHsFabjxiI,
2017,"Las Vegas, NV",Andrzej Bialecki,Lucidworks,,Monitoring metrics in Solr 6 and 7,Solr Feature Deep Dive,"This session will present in detail how the metrics subsystem in Solr 6.5 and 7 is designed and implemented, what kind of insights it provides into Solr state and performance, as well as how it integrates with external monitoring platforms., with examples of standard and custom integrations. It will also explain how metrics are reported and aggregated in SolrCloud, and how this information is used for cluster auto-scaling.",https://youtu.be/BYwgSk79wwk,https://www.slideshare.net/lucidworks/solr-metrics-andrzej-biaecki-lucidworks
2017,"Las Vegas, NV",Bjarki Holm,Lucidworks,,Data to Application in Minutes,Solr for Business,"Good user experience is critical to the success of any search application. All too often, however, the design of the user interface is left until the last phase (and last dollar) of a project, even though this is what ultimately determines the value of a solution to its users. A part of the problem is that it's hard to capture user experience in wireframes from the outset. People prefer to interact directly with live data, rather than mock-ups, and as a project progresses, the data tends to evolve which impacts the UI requirements. In this session we will talk about the importance of UX in the design of search applications, ranging from simple keyword search to more complex solutions in analytics and discovery. We will discuss common UX patterns and paradigms in search, and show how anyone, irrespective of design ability, can be guided to choosing the right patterns for their data. We will also demo how we can apply these principles in practice, by quickly building a mobile-ready search application in a matter of minutes, using the Fusion App Studio.",https://youtu.be/K5r1LZGNqm8,
2017,"Las Vegas, NV","Cao Manh Dat, Shalin Mangar",Lucidworks,,The New Replica Types of Solr 7.0,Solr Feature Deep Dive,"Learn about new replicas types of Solr 7.0, which are very suitable for high load clusters (heavily indexed and searched) with the tradeoff of soft-commit.",https://youtu.be/XqfTjd9KDWU,https://www.slideshare.net/lucidworks/the-new-replica-types-in-solr-7-cao-manh-dat-shalin-shekhar-mangar-lucidworks
2017,"Las Vegas, NV",Chris Hostetter,Lucidworks,,Lifecycle of a Solr Search Request,Solr Feature Deep Dive,"This intermediate session for existing Solr users will provide a Deep Dive look into the lifecycle of a Solr Search Request.  We will drill down through each layer of code, discussing what happens at each stage -- including when & how inter-node communication takes place in a multi-node SolrCloud cluster.  Along the way, we will also review the various places where users can configure existing (or custom written) plugins to override or amend the default behavior.",https://youtu.be/qItRilJLj5o,https://www.slideshare.net/lucidworks/lifecycle-of-a-solr-search-request-chris-hoss-hostetter-lucidworks
2017,"Las Vegas, NV",David Arthur,Lucidworks,,Building Fusion: Trials and Tribulations of Developing Enterprise Search Software,Lightning Talk,Building Fusion: Trials and Tribulations of Developing Enterprise Search Software,https://youtu.be/44v2WljG1R0,
2017,"Las Vegas, NV",Erik Hatcher,Lucidworks,,Payloads in Solr,Solr Feature Deep Dive,"Solr now supports a powerful feature of Lucene, payloads.  A payload provides optional term-position metadata that can be incorporated in search results, ranking, sorting, and faceting.  Payload use cases include e-commerce store-specific pricing and custom term weighting.  (This session summary is TBD - let's converse and flesh this out - wanted to submit before deadline but work on this feature is still in progress - see SOLR-1485)",https://youtu.be/EUi9VHS8KIc,https://www.slideshare.net/lucidworks/payloads-in-solr-erik-hatcher-lucidworks
2017,"Las Vegas, NV","Kevin Cowan, Steve Harris",Lucidworks,,Securing Solr: Tips and Tricks and Things You Really Ought to Know,Solr Best Practices,"The talk will be based largely on the content of this blog:  https://lucidworks.com/2017/04/14/securing-solr-tips-tricks-and-other-things-you-really-need-to-know/  And this one:  https://lucidworks.zendesk.com/knowledge/articles/115004255408/en-us?brand_id=2289156  As of release 5.2, Solr comes out-of-the-box with both authentication and authorization APIs, allowing you to define users, roles and permissions, using the RuleBasedAuthorizationPlugin and the BasicAuthPlugin.  That's the good news.  The not-as-good-news is that these plug-ins, while powerful, are a bit counter-intuitive when it comes to configuration.  Thus we took it upon ourselves to spend some quality time with the Solr security architecture and understand a) just how this framework operates; and  b) to identify it's various idiosyncrasies.  To that end, we've compiled a handy list of things to keep in mind when setting up and/or managing your Solr security. ",https://youtu.be/4d5z0ryhABs,
2017,"Las Vegas, NV",Kiran Chiturri,Lucidworks,,Faster Data Analytics with Apache Spark using Apache Solr,Integrations / Complimentary Technologies,"Apache Spark is a fast and general engine for big data processing, with built-in modules for streaming, SQL, machine learning and graph processing. Spark SQL allows users to execute relation queries in Spark with distributed in-memory computations. Though Spark gives us faster in-memory computations, Solr is blazing fast for some analytic queries. In this talk, we will take a deep dive into how to optimize the SQL queries from Spark to Solr by plugging into the Spark LogicalPlanner using pushdown strategies. The key take aways from the talk will be:  1. How to perform Spark SQL queries with Apache Solr? 2. What happens inside a Spark SQL query? 3. How to plug into Spark Logical Planner? 4. What type of push-down strategies are optimal with Solr? 5. Examples of push-down strategies",https://youtu.be/I0Sd5pKn7Dw,https://www.slideshare.net/lucidworks/faster-data-analytics-with-apache-spark-using-apache-solr-kiran-chitturi-lucidworks/edit?src=slideview&type=privacy
2017,"Las Vegas, NV",Steve Rowe,Lucidworks,,Exploring Direct Concept Search,Solr & Machine Learning ,"This session will present experiments in extending Lucene's Dimensional Points to directly store word embedding vectors as document terms, enabling direct concept search by mapping terms and phrases at index and query time.  The effects of varying distance in the word embedding space at query time will be explored.  Impacts on retrieval effectiveness and speed will be presented.",https://youtu.be/ELQ3T_8E5jE,https://www.slideshare.net/lucidworks/exploring-direct-concept-search-steve-rowe-lucidworks
2017,"Las Vegas, NV",Ted Sullivan,Lucidworks,,"A Multifaceted Look At Faceting - Using facets ""Under the Hood"" to Facilitate  Relevant Search",Solr Feature Deep Dive,"The talk will discuss some novel techniques that reveal additional ways by which Solr facets can enrich search experiences. Facets are a tried-and-true UI navigation and visualization tool. They are also used to build slick dashboards with bar and pie charts, using pivot facets, range and function queries, facet statistics and so forth. That Solr facets are determined at query time is crucial in this respect! Facet metadata can also be used to drive query intent detection that borders on NLP, and to create contextual sidecar indexes for semantically based, multi-field query typeaheads with real-time suggestion boosting. They can also be used to explore term relatedness and to develop subject classifiers based on ""keyword clusters"" that provide excellent unsupervised machine learning capabilities. So facets have a role not just at query time, but can also help to drive the indexing analytic processes that fuel content and thus user experience enrichment - by feeding semantic contexts revealed by facets back into sidecar collections or the source collections that they came from. One result is - you guessed it - BETTER FACETS - a ""virtuous"" cycle to be sure!",https://youtu.be/vqoShw5E0nY,https://www.slideshare.net/lucidworks/a-multifaceted-look-at-faceting-ted-sullivan-lucidworks
2017,"Las Vegas, NV",Timothy Potter,Lucidworks,,Running Solr at Memory Speed with Alluxio,Integrations / Complimentary Technologies,"In this talk, I introduce Alluxio, the fastest growing open source project in the big data ecosystem, and show how to leverage it for optimizing Solr performance. I'll begin with a brief introduction about how Alluxio works and why it's interesting for the Solr community. Next, I describe how to run Solr on Alluxio and cover basic integration scenarios. Lastly, I provide some performance comparisons between running Solr on Alluxio vs. a local FS and HDFS. Attendees will come away with a new toolset to help them use Solr to tackle a wide array of big data problems.",https://youtu.be/P5skIa3Y7go,https://www.slideshare.net/lucidworks/running-solr-at-memory-speed-with-alluxio-timothy-potter-lucidworks
2017,"Las Vegas, NV",Will Hayes,Lucidworks,,Opening Remarks,General Session,Opening Remarks,https://youtu.be/IR7WyIIg4Gc,
2017,"Las Vegas, NV","Joel Bernstein, Dennis Gove",Alfresco,,The Evolution of Solr Streaming Expressions: from Stream Processing to Distributed Functional Programming,Solr Feature Deep Dive,"Streaming Expressions started from a few simple concepts:  * Stream sources that originate streams * Stream decorators that transform streams * A simple functional syntax to tie it all together  Streaming Expressions now have over 80 expressions and evaluators, conditional logic, variables and data structures. These functions form the basis of a sophisticated functional programming language that supports a large number of parallel computing use cases including: Parallel SQL, MapReduce, Machine Learning, Anomaly Detection, Streaming NLP, Graph Traversal and Time Series Analysis.  This talk will cover the evolution of the language to date and where Streaming Expressions will likely be headed in the future.",https://youtu.be/kTNe3TaqFvo,
2017,"Las Vegas, NV","Kevin Vondekamp, Grant Ingersoll",Appen,,Why Human-Generated Data Matters for Search,Integrations / Complimentary Technologies,"Search is a critical component of any effective website or application, connecting users to the data they need to make decisions, whether it's to find documents, do research or complete an online purchase.  Modern search engines have evolved significantly in the past 5 years, incorporating machine learning and artificial intelligence techniques in all aspects of document and query processing, as well as in user profiling and personalization.  These techniques require large volumes of high quality training and evaluation data in order to be effective.  In this session, you'll hear Kevin Vondemkamp, Vice President, Web, Social & eCommerce of Appen and Grant Ingersoll, CTO of Lucidworks discuss how Lucidworks leverages Appen's crowdsourcing capabilities to enhance its machine learning technology to improve all aspects of the search experience. ",https://youtu.be/ce0WNLdzYZk,
2017,"Las Vegas, NV",Anshum Gupta,Apple,,Designing a search platform? Ask These Questions First!,Solr Best Practices,"Search is a rather complex problem to solve and this becomes  even trickier when you are building a platform to support multiple use cases. An essential part of designing such platforms is ""asking the right questions"". This talk will cover a wide range of questions that should be addressed, based on the audience of the platform, while designing a search platform. Ranging from scalability questions, in terms of being able to support more data and more users, to usability questions, like auto-detection of fields and if it's a good thing to have, this talk will cover a variety of aspects. Anshum will also talk about security and how it might be critical and what to think about in terms of both simple security and multi-tenancy based on the use case you might have. At a high level, Anshum will share his learnings around scalability, usability, and security that he has accumulated over the years at multiple large and small organizations.",https://youtu.be/DhMz2t8X9XU,
2017,"Las Vegas, NV",Tomâ€¡s Fernâ€¡ndez LÅ¡bbe,Apple,,SolrCloud meets Master/Slave Replication,Solr Feature Deep Dive,"For the majority of the cases, current SolrCloud distributed indexing works great. There is a subset of use cases for which the legacy Master/Slave replication may be a better fit, like cases where NRT is not required, and where read availability is more important than consistency. For such cases we are adding to Solr a way to choose different types of replicas, that treat updates in different ways. With a combination of replica types, one can create a SolrCloud cluster that behaves like a Master/Slave architecture of Solr < 4.0 and provides separation of responsibilities (search vs index) while still getting most of the SolrCloud benefits, like high availability of writes, replica discovery, collections API, etc. This talk will be a deep dive into the Replica Type feature, reasons for implementing it, differences between the existing types and how/why one would choose to use them, and implementation details of the feature.",https://youtu.be/XIb8X3MwVKc,
2017,"Las Vegas, NV",Christine Poerschke,Bloomberg LP,,Learning-to-Rank with Apache Solr and Bees,Solr & Machine Learning ,"Is ""machine learning + open source search + social insects"" a bit of a gamble for a talk topic? Absolutely, this conference is in Las Vegas after all!  Join Lucene/Solr committer and beekeeper Christine for an easy step-by-step walk through Apache Solr's Learning-to-Rank plug-in. No prior Solr or machine learning experience needed. We will index some bees, err, I mean honey and bee related tweets, and then use those documents to come up with different machine learnt re-ranking models to improve search results' relevance.",https://youtu.be/OJJe-OWHjfI,https://www.slideshare.net/lucidworks/learningtorank-with-apache-solr-bees-christine-poerschke-bloomberg/edit?src=slideview&type=privacy
2017,"Las Vegas, NV",Houston Putnam,Bloomberg LP,,Analytics at Scale with the Analytics Component 2.0,Solr Feature Deep Dive,"In this talk we will discuss the next iteration of the Solr Analytics Component. The analytics component gives users the ability to compute complex analytics, in real-time, over result sets. The focus of the new version of the analytics components was support for analytics on distributed/sharded collections while maintaining the capabilities and performance of the original. Several additional features have been added including faceting over field/function expressions, support for multi-value field expressions and significant performance improvements for high cardinality facets.  We will briefly review the capabilities of the original analytics component, followed by a demonstration of the features and use cases this new release enables.  We will discuss the use cases that the analytics component is better suited for than Solr streaming. Finally, we will examine the internals of the component and how to best structure analytics requests in order to maximize performance.",https://youtu.be/SSoVGx8m1P0,https://www.slideshare.net/lucidworks/analytics-at-scale-with-the-analytics-component-20-houston-putman-bloomberg-lp
2017,"Las Vegas, NV",Jake Wagner,Bluestem Brands Inc. ,,Fusion Ecommerce Case Study: Bluestem Brands Inc.,Solr for Business,"Over the last 18 months, in partnership with Lucidworks, Bluestem Brands has been treated to a whirlwind tour of search engine modernization. Join us as we explore the highs and the lows of a rapidly exploding index size, strict performance goals, well-meaning work arounds, a Fusion implementation, the holiday sales season, and the business transformations that Fusion backed functionality has since motivated.  From problems to pipelines, sales to servers, and couches to sharks; weÃ•re going to cover it all.",https://youtu.be/Dxg_HAia5BY,https://www.slideshare.net/secret/BWy5iAFmGkFNf
2017,"Las Vegas, NV",Patrick Beaucamp,Bpm-Conseil,,R to forecast Solr activity,Solr Best Practices,"This session is a deep review on Solr performance management and how to set up a scalable Solr infrastructure that will match with future user's activity.  Taking advantage of solr logs and time series functions in R, we can build custom models to analyze Solr activity and highlight periodicity. Using other kinds of R functions, such as exception management, we can highlight activity peak and keep it or not in the predictive model. Using the Association function in R, we can analyze user search behavior (such as cascading search, one search criteria leading to another facet of search).  Once a user's activity is statistically validated (exploration and discovery techniques using Dashboard, Olap, etc.), we can develop custom predictive models in R to forecast user activity and adapt Solr infrastructure to this expected workload.  The last piece of the framework is to use a comparison model between forecast and reality to adjust the custom model and address machine learning points of interest.",https://youtu.be/NF5EJV8TKFY,https://www.slideshare.net/lucidworks/r-to-forecast-solr-activity-patrick-beaucamp-bpmconseil
2017,"Las Vegas, NV","Srini Samudrala, Khalid Imam",Cisco Systems,,SOLR for Enterprise channels business,Solr for Business,"What matters in current world? Time Speed Performance Framework  With SOLR, the approach is to automate the mechanism in channels business to handle huge sets of data with scalable framework to reduce development lifecycle and auto expose data elements across different technologies (Hadoop, java, solr, oracle).  We are going to discuss this in detail during our session and show how to thread multiple technologies together.  ",,
2017,"Las Vegas, NV",Mano Kovacs,Cloudera,,SolrCloud Consistency and Recovery Internals,Solr Feature Deep Dive,"SolrCloud is a distributed search system, but how does it ensure that replicated data remains consistent? How does Solr avoid data loss when hardware inevitably fails? And how do temporary outages affect the availability of services?  In this talk, we will begin with a foundation of the relevant replication and leader election details before moving on to cover how Solr addresses failures and what recovery steps the cluster can automatically perform. We will examine the different classes of failure to better understand which ones are recoverable automatically, and which ones will require manual intervention by an operator. And in doing so, we will highlight which manual steps are safe and which ones carry more risk, as well as potential future improvements to the automated processes.",https://youtu.be/ofxBegvIkIo,
2017,"Las Vegas, NV",Mark Miller,Cloudera,,Wrangling Solr Tests with Beasting Test Reports via BeastIt,Lightning Talk,Wrangling Solr Tests with Beasting Test Reports via BeastIt,https://youtu.be/44v2WljG1R0,
2017,"Las Vegas, NV",Yonik Seeley,Cloudera,,Analytics and Graph Traversal with Solr,Solr Feature Deep Dive,"Analytics in Apache Solr continue to advance at a rapid pace, intersecting with other features such as faceted search and graph traversal.  This talk will cover new advances in these areas as well as streaming expressions, parallel SQL,  and the trade-offs and scalability characteristics of different approaches to real-time analytics.",https://youtu.be/gtoF1MFk2Vk,https://www.slideshare.net/lucidworks/analytics-and-graph-traversal-with-solr-yonik-seeley-cloudera/edit?src=slideview&type=privacy
2017,"Las Vegas, NV",Hrishikesh Gadre,Cloudera Inc.,,Apache Solr: Upgrading Your Upgrade Experience,Solr Best Practices,"Despite widespread enterprise adoption, Solr lacks automated upgrade tooling. It has long been a challenge for users to understand the implications of a Solr upgrade. Users must manually review the Solr release notes to identify configuration changes either to fix backwards incompatibilities or to utilize latest features in the new version. Additionally, users must identify a way to migrate existing index data to the new version (either via an index upgrade or re-indexing the raw data). Clearly, the Solr upgrade process can be cumbersome and error-prone.  In this talk, we will provide an overview of the typical challenges faced by users during a Solr upgrade. We will discuss a strategy that uses a set of config migration tools, as well as the backup and disaster recovery capability to help users navigate the Solr upgrade process reliably and with peace of mind. Finally, we will share common tips and tricks to remember while planning a Solr upgrade.",https://youtu.be/GHsHrXqx6oA,https://www.slideshare.net/lucidworks/apache-solr-upgrading-your-upgrade-experience-hrishikesh-gadre-lucidworks
2017,"Las Vegas, NV",Jan Hoydal,Comnivent,,SolrÃ•s missing plugin ecosystem,Solr Feature Deep Dive,"Until now, Solr plugins were mainly a developer-level concept of Java classes implementing certain interfaces. They were hard to discover, being spread around the internet, hard to install, with version conflicts and dependencies, and often youÃ•d have to build it yourself.   The improved plugin system being proposed in this talk utilizes PF4J to add bundle packaging (zip/jar), plugin discovery (repositories), one-line install/upgrade and automatic version compatibility checks. Think of it as Homebrew or Apt-Get for Solr :) The hope is that this will encourage hundreds of new plugins being created and thus give Solr developers a sense of community and a new Ã’stageÃ“ to perform on.  IÃ•ll demo the current state of things with searching, installing, upgrading and uninstalling plugins both from bin/solr command line and from the Admin UI. You should attend this talk if you just want a Ã’WOW, Give It To MeÃ“ experience or if you want to help out maturing the feature! ",https://youtu.be/hZKcULlZEQQ,
2017,"Las Vegas, NV",Simon Hughes,DHI \ Dice.com,,Learning to Rank without Re-Ranking - Learning a Better Similarity Function at Dice.com,Solr & Machine Learning ,"The most common approach to implementing learning to rank (LTR) is to use a re-ranking model to execute a search using the search engine, and then re-rank the top n documents using a machine learning model. Machine learning models are typically not fast enough to be used to rank the entire corpus, so re-ranking allows LTR models to be implemented efficiently. However, some relevant documents may lie outside of the top n documents, especially if there is a recall issue. Furthermore, re-ranking the top results adds computation time, and requires use of a plugin to incorporate the model into the search engine. An alternate approach is to use machine learning techniques to learn a custom similarity function to replace the one implemented in the search engine. This can be used to rank all documents in the collection in an efficient and scalable manner.  Training an LTR model is difficult â€°Ã›Ã’ small improvements produced by the LTR model often result in fetching new search results which have no associated relevancy judgements, making learning using a fixed set of relevancy judgements difficult. We will outline a number of solutions to this problem, including use of search log data, and reformulating the ranking problem.",https://youtu.be/-uiQY2Zatjo,https://www.slideshare.net/lucidworks/personalized-search-and-job-recommendations-simon-hughes-dicecom
2017,"Las Vegas, NV",Mikhail Khludnev,EPAM,,Search LIKE %SQL%,Solr Feature Deep Dive,"Sometimes customers ask to search for substring occurrence LIKE %SQL%, completely ignoring the idea of keyword search.  We can also face this challenge in a chemical corpus and bioinformatic space.   Searching LIKE %SQL% is surprisingly hard in search engines. During the session, we'll look at the data structures behind Lucene index, and discuss what makes such search so heavy. Then, we describe common, but inefficient techniques like edge N-gramming and reversing.  Finally, we'll look how to address it with the built-in algorithms, reducing customization as possible.   Note: this talk is not about introducing suffix arrays, and has nothing with the recent Solr SQL functionality.",https://youtu.be/FQPKAmh0s_I,https://www.slideshare.net/lucidworks/search-like-sql-mikhail-khludnev-epam
2017,"Las Vegas, NV",Daniel Gomez Villanueva,Findwise,,Relevance in the wild,Solr Best Practices,"Let's talk relevance. The one aspect of search that users perceive directly and will determine their satisfaction with search.  Solr allows us to steer every aspect of the calculation of the score to decide in what order we are getting results. There are many aspects that can be taken into account when determining which is the most relevant document for a user specific need. Moreover, the most important aspect is to go only forward in steadily improving relevance, and being sure of every step by having the proper toolbox to evaluate results.  In this talk we are going to describe a long list of examples used in dozens of real projects that use many types of signals from the user, documents and apply them using the wide range of features available in Solr. We will define relevance testing, a way of working with it that guarantees control about the state of relevance, and quantitative evaluation of its results. At the end of the presentation you will have the tools and methods to know what information to use and how to use it to get the relevant information to the top.",https://youtu.be/Tf3tEn1bZfM,https://www.slideshare.net/lucidworks/relevance-in-the-wild-daniel-gomez-vilanueva-findwise
2017,"Las Vegas, NV",Sean Bethune,Fred Hutch Cancer Research Center,,Accelerating Science Using 21st Century Research,Lightning Talk,Accelerating Science Using 21st Century Research,https://youtu.be/44v2WljG1R0,
2017,"Las Vegas, NV",Shai Erera,IBM,,Passage Search: the Answer to Your User Questions!,Solr Feature Deep Dive,"Searching for top-ranking documents with Solr is dead-simple: submit your query and Solr will spin its wheels to match your query against documents, score each one and return a ranked list of them. But what if your application requires searching for, say, a paragraph or a sentence? Indexing those as documents is not always possible, as well not very flexible, especially if different users require searching for different-sized portions of the documents.  In this talk I will describe the problem of Passage search, what use cases it addresses, and how it differs from traditional Document search with highlighting. I will also review multiple implementation approaches, all of which can be implemented at the client side, without modifying out-of-the-box Solr code. I will then conclude with evaluation results of each approach.",https://youtu.be/7Gp4AmvuxO8,https://www.slideshare.net/lucidworks/passage-search-the-answer-to-your-user-questions-shai-erera-ibm
2017,"Las Vegas, NV","Praveen Settipalli, Reddy Yakkanti",Kohl's,,"Search Evolution at KohlÃ•s - Personalization, Machine Learning and Chatbots",Solr for Business,,,
2017,"Las Vegas, NV","Rohit Kanchan, Michael Schumann",Marketo,,Move from Mysql to Solr with NRT Data at Marketo,Solr for Business,This talk will cover:  - Marketo's Solr architecture. - Queries which used to take 1hr against Mysql now return results with in 5 seconds - How near real time data is available in Solr by using Spark Streaming and Kafka - How Marketo classifies their customers and gives them their own core in Solr.,https://youtu.be/JM2Lug0akaM,
2017,"Las Vegas, NV",Marc Ubaldino,MITRE,,Discovering World Geography in Your Data,Lightning Talk,Discovering World Geography in Your Data,https://youtu.be/44v2WljG1R0,
2017,"Las Vegas, NV",Dana Lewis,Open APS,,#WeAreNotWaiting: Using open source to change healthcare,General Session,"What if you could use open source technology to make a difference in ways previously thought impossible? And if you could make a difference in someone's life (like your own): would you wait for permission, or just do it? Learn how a community developed around the #WeAreNotWaiting movement to make a difference with open source technology to improve life with diabetes, and how these efforts are paving the way for changing the way we all can contribute to changing healthcare.",https://youtu.be/G-puWmsuib0,https://www.slideshare.net/lucidworks/vegascom-and-fusion
2017,"Las Vegas, NV",Doug Turnbull,OpenSource Connections,,Taxonomical Semantical Magical Search,Solr Feature Deep Dive,"Search practitioners often overlook the user's entire journey to seek and find. Users strike out with broad searches, unsure what they'll find. They begin with broader concepts (such as 'laptop bag'). The results give them an overview of what's possible. They refine with finer grained distinctions. 'Childs Laptop bag' or 'satchel bag.' They continue to refine to narrower or adjacent concepts until they purchase or give up.  In this talk, I walk through how we build semantic search with Solr based on how users mentally structure your information. They key is taxonomies! I walk through how we generate taxonomies from search logs to build hierarchical synonyms, hypernyms, and hyponyms. I then discuss how manipulate relevance scoring to get the effect user's expect: high recall and a broad overview on broad queries and high precision on narrower queries. I go on to discuss a practice for refining managed taxonomies based on evolving user behavior, ever evolving to findability nirvana!",https://youtu.be/90F30PS-884,
2017,"Las Vegas, NV",Eric Pugh,OpenSource Connections,,Search Relevance Organizational Maturity Model,Solr for Business,"In this talk, Eric Pugh, long-time Solr practitioner discusses his broad experience across hundreds of organizations delivering smart search. He introduces a maturity model to help think through where your team is on it's road to smarter search.  Smarter search drives value to your business. Delivering search that matches users to the right content (jobs, products, articles, whatever) is what you care about. But organizations often get stuck getting there -- why? Turns out you need quite a number of ingredients to deliver tremendous search: You need the intelligence to understand what users are searching for and whether they're satisfied. You need the domain expertise, infrastructure, and data science to extract meaningful features from your content, user personas, and user queries. Well and more mundanely you need to install, scale, and operate a search engine!  All of this can send your head spinning! This talk will give you the tools to see the search forest for the trees. Come and learn from Eric your next steps on the road to delivering great search!",https://youtu.be/mGYas9nUSiE,https://www.slideshare.net/lucidworks/search-relevance-organizational-maturity-model-eric-pugh-opensource-connections
2017,"Las Vegas, NV",JP Sherman,Red Hat,,Search as a Force Multiplier: Measuring Search Success for Key Stakeholders,Solr for Business,"Customers, managers and content creators are all invested in the quality of the search results. The challenge is that each group has different expectations from search and different priorities for measuring search success. Learn how to quantify each type of success metric to provide clear value to each user group. These data-driven success metric models can quantify success and provide information to make better informed search and content decisions.",https://youtu.be/8JZA_Vr-FZs,
2017,"Las Vegas, NV","Chris Slowe, Nick Caldwell, Luis Bitencourt-Emilio",Reddit,,The Search for Better Search at Reddit,General Session,The Search for Better Search at Reddit,https://youtu.be/_WTyqS2Eb2E,
2017,"Las Vegas, NV","Dale Smith, Chris Phillips",REI,,Our Tale from the Trail of Shadows at REI Co-op,Solr for Business,"Is it possible to build something fast and cheap while putting quality first? Join us as we share our journey of a successful upgrade to the REI Co-Op Digital E-commerce search experience. You will learn how our team was structured for success, and how we earned the trust of the business team, allowing us to work efficiently with few impediments. We'll take a technical dive into some of the tools and methods that we used to validate our new Solr search platform, which ultimately allowed us to execute the holy grail of software upgrades - an uneventful one!",https://youtu.be/a12beliwb3U,https://www.slideshare.net/lucidworks/our-tale-from-the-trail-of-shadows-at-rei-coop-chris-phillips-dale-smith-rei-coop
2017,"Las Vegas, NV","Zach Alexander, Tracy Backes",Salesforce.com,,Learning to Rank from Clicks,Solr & Machine Learning ,"This talk introduces the mathematics behind the effort at Salesforce to improve search relevance using machine learning.   First, we discuss a new approach for search ranking. Much of the active research in this field has focused on the use of a large amount of labeled data. Specifically, human beings need to sift through tens of thousands of queries---along with returned results---and mark each result on a scale from `not relevant' to `extremely relevant'. At Salesforce, we have developed a novel machine learning approach, for learning a ranking function, that does not require labeled data.  Second, we discuss the mathematical foundations of our AB testing program. Since user clicks do not follow any standard distribution, we rely on extensive simulations to estimate the power of AB tests and evaluate the significance of the results.",https://youtu.be/pDY2lReiCqk,
2017,"Las Vegas, NV","Pengchu Zhang, John Herzer",Sandia National Laboratories,,"An Intelligent, Personalized Information Retrieval Environment",Solr & Machine Learning ,"Current enterprise search engines return prioritized results to users based on the enginesÃ• internal ranking algorithms. The unique attributes of the user and documents are not taken into account. To improve usersÃ• information retrieval experience, we are creating an environment that allows users to retrieve information that best matches their personal, time-sensitive needs. To achieve this level of personalization, analysis of documents published by the members of the work force is conducted utilizing clustering and classification algorithms. By combining users' past information retrieval behaviors with document metadata generated by our analytic techniques, we can build predictive models. These models are able to predict the information needed by specific groups of users and recommend appropriate content. We utilize state-of-the-art technologies, including Spark machine learning in a Hadoop environment and Convolutional Neural Networks, a deep learning architecture, in order to extract useful features from a large corpus of unstructured data. In addition, we developed and improved several machine learning algorithms in clustering, classification and auto labeling.  Building profiles of user's information retrieval activity required the development of an extensive query and click tracking facility. In order to achieve a highly integrated information retrieval environment, we are replacing our home grown query and click tracking database with the Fusion Signal capabilities. We will discuss how we approached the task of migrating from an internally developed logging system to the Fusion platform.  ",,
2017,"Las Vegas, NV",Clay Pryor,Sandia National Labs,,Evaluation of Lucidworks Fusion for Enterprise Search at Sandia National Laboratories,Solr for Business,"In the past, Sandia National Labs has used several COTS products for enterprise search.  A few years ago the decision was made to abandon all COTS Enterprise Search products and use Solr and custom in-house developed applications for our enterprise search needs. The enterprise search marketplace has changed since that decision was made and the expectations of our search users have grown dramatically, making it hard for us to keep up with expectations.  Lucidworks Fusion looked to us like a viable product that could be used to help us achieve our enterprise search goals at a reasonable cost.  We conducted a three month ""Proof of Concept"" study to evaluate Lucidworks Fusion against our current and projected future requirements.  This talk will discuss how we evaluated Lucidworks Fusion, what we looked at in terms of our requirements, and the results of our evaluation.",,
2017,"Las Vegas, NV",Rafal Kuc,"Sematext Group, Inc",,Optimize Is (Not) Bad For You - Deep Dive Into The Segment Merge Abyss,Solr Best Practices,"They say optimize is bad for you, they say you shouldn't do it, they say it will invalidate operating system caches and make your system suffer. This is all true, but is it true in all cases? In this talk we will look closer on what optimize or better called force merge does to your Solr search engine. You will learn what segments are, how they are built and how they are used by Lucene and Solr for searching. We will discuss real-life performance implications regarding Solr collections that have many segments on a single node and compare that to the Solr where the number of segments is moderate and low. We will see what we can do to tune the merging process to trade off indexing performance for better query performance and what pitfalls are there waiting for us. Finally, at the end of the talk we will discuss possibilities of running force merge to avoid system disruption and still benefit from query performance boost that single segment index provides.",https://youtu.be/poARdta7Z_s,https://www.slideshare.net/lucidworks/optimize-is-not-bad-for-you-rafa-ku-sematext-group-inc-80474261
2017,"Las Vegas, NV",Radu Gheorghe,"Sematext Group, Inc.",,"Solr on Docker: the Good, the Bad and the Ugly",Integrations / Complimentary Technologies,"This session has two goals: first, we'll discuss the tradeoffs for running Solr on Docker. For example, you get dynamic allocation of operating system caches, but you also get some CPU overhead. We'll keep in mind that Solr nodes tend to be different than your average container: Solr is usually long running, takes quite some RSS and a lot of virtual memory. This will imply, for example, that it makes more sense to use Docker on big physical boxes than on configurable-size VMs (like Amazon EC2).  The second goal is to discuss issues with deploying Solr on Docker and how to work around them. For example, many older (and some of the newer) combinations of Docker, Linux Kernel and JVM have memory leaks. We'll go over Docker operations best practices, such as using container limits to cap memory usage and prevent the host OOM killer from terminating a memory-consuming process - usually a Solr node. Or running Docker in Swarm mode over multiple smaller boxes to limit the spread of a single issue.",https://youtu.be/PC8mYweMgV4,https://www.slideshare.net/lucidworks/solr-on-docker-the-good-the-bad-and-the-ugly-radu-gheorghe-sematext-group-inc
2017,"Las Vegas, NV",Torsten Koester,shopping24 internet group,,Context driven search ranking and faceting,Solr for Business,"In e-commerce, when searching over a wide range of products, sorting your search result is crucial to your business. You most likely want to sort your search result depending on the search context - like the dominating category or the user's search or order history. We built a Solr plugin to determine the current category ""in flight"" and change sorting and facetting of the current query without adding any overhead to the query. In this talk I will guide you through the implementation and give examples on how to add search context to your Solr query.",https://youtu.be/LoK_u6wrdDs,https://www.slideshare.net/lucidworks/context-driven-search-ranking-and-faceting-torsten-kster-shopping24-internet-group
2017,"Las Vegas, NV","Mayank Gupta, Gopal Patwa",Stubhub,,Event Search at Stubhub,Solr for Business,"This session presents event search at Stubhub. Event search at Stubhub has significantly evolved over the last few years and in this talk, we will go over how we use machine learning to assist users in finding & selecting the right event. Specifically, we will go over some of the NLP, relevancy and ranking algorithms that we have built on top of SolrCloud and also how we use SolrCloud to power our ChatBot and near-real time indexing platform. Using a combination of Solr and machine learning, we were able to connect users with inspiring live events and hence improve conversion.",https://youtu.be/KilplSij-_Y,
2017,"Las Vegas, NV",Ilayaraja Prabakaran,Target Corp,,Integrating clickstream data in SOLR for ranking and dynamic facet optimization,Solr for Business,"In this talk, I will be covering application of clickstream data for building a ranking technique to re-order search results for target.com product search. Along with this, another application of clickstream data to optimize search facet engagement will be discussed.  Ranking with clickstream data: Clickstream data provides implicit guest feedback on search results. In this talk, I will cover extracting clickstream events to derive ranking score for a given search term and item based on the previous click history. Below is the list of action items that will be discussed:  Offline data computation and indexing: - Defining clickstream events: clicks, conversion - Spark implementation for clickstream batch processing - Reverse indexing search term and rank score to SOLR  Query time ranking: - Apply click scoring using SOLR function and boost queries - Merge click score with default lucene tf/idf similarity score  Facet Optimization: Faceted search increases conversion. Showing the right facets is key to improved user engagement and a better search experience. In this talk, I will discuss how click stream data can be used to derive function to reorder facets to optimize user engagement. Also, I will go over learning model for discovering the right facets for a query and filtering irrelevant facets. The model incrementally learns from previous iterations to dynamically adjust the ranking of facets.",https://www.slideshare.net/secret/BWy5iAFmGkFNf,https://www.slideshare.net/lucidworks/integrating-clickstream-data-into-solr-for-ranking-and-dynamic-facet-optimization-ilayaraja-prabakaran-target
2017,"Las Vegas, NV","Ilamgumaran Velayuthan Karunanithi, Navin Anandaraj",The Home Depot,,Running a Highly Available and Scalable Solr Platform in the Cloud,Solr for Business,"Home Depot's online search platform which powers our ecommerce platform requires an engine that can handle high volume reads, real time indexing and batch updates on nodes taking live traffic. Leveraging Solr Cloud's distributed architecture and google cloud infrastructure, we were able to provision an HA and scalable Solr cluster across multi regions to support the high volume reads and indexing.   This session will focus on: the provisioning and automation of building a Solr cluster in the cloud; challenges involved in automation of Solr cluster creations on cloud platforms like Google Cloud Platform and how our team overcame them; replica management in ephemeral cloud infrastructure; how to plug Solr into Google Cloud Instance Group infrastructure; and learnings from usage of Go language plugins for Zookeeper and in house Go language collection management package for Solr.   We'll also cover patterns on routing traffic to a newly provisioned cluster without losing real time indexing feeds to support version upgrades or any changes. We'll talk about our performance learnings and optimizations which helped meet our aggressive SLOs. In the end we'll also cover the metrics, alerting and automated recovery patterns we implemented for Solr, Zookeeper and Fusion stack to ensure reliability.",,
2017,"Las Vegas, NV","Rongkai Zhao, Rajdeep Mondal",The Home Depot,,User behavior driven intelligent query re-ranking and suggestion,Solr & Machine Learning,"With the advancements in machine learning, Solr is becoming more intelligent. In this talk, two user behavior driven features are discussed. Search result straight coming out of index may not be optimal. When those results are re-ordered by price, review score, arrival time etc, results are further degraded. An L2R (learn to rank) method is developed to learn from user behavior and the learnt model re-ranks search result in an optimal way. Both text features and image features are converted into vector forms and combined to train ensemble models. The method can be applied to queries with or without user behavior and can also be used to intelligently sort search results by criteria other than search relevancy. The second user behavior driven feature is type-ahead, also known as auto-complete, autofill, auto-suggest. Traditional methods are based on statistics from query log and product catalog. The new method leverages usersÃ• selection of the predicted queries along with the location and time of the interaction to provide more relevant and accurate type ahead suggestions. Both features showcase how machine learning meets solr to render a more powerful overall search experience in an e-Commerce website.  ",,
2017,"Las Vegas, NV","Ashwani Kapoor, Girish Gudla",Trulia,,Real Time Indexing Pipeline,Solr for Business,"In the session, we will explain Trulia's (Zillow Group) search infrastructure architecture which supports real time property updates with all changes visible to end users (renters or sellers) in less than 5 minutes. We will cover the technical architecture of the ""Real Time Indexing Pipeline"", which is built using Solr Cloud, Lucene, Storm, Kafka, Redis, and micro-services all hosted on AWS. This talk will explore how we achieved and built a scalable search infrastructure and pipeline and how we eliminated any cache at search to avoid a delay in data visibility to users. We will also discuss how we made deployment easy and fast to expand and scale.",https://youtu.be/h8SzL938xx8,
2017,"Las Vegas, NV","Ishan Chattopadhyaya, Vivek Narang",Various,,Solr Benchmarking Suite,Lightning Talk,Solr Benchmarking Suite,https://youtu.be/44v2WljG1R0,
2017,"Las Vegas, NV","Scott Cote, Trevor Grant",Various,,Solr and Machine Vision,Solr & Machine Learning ,"Facial recognition in production is difficult because neural networks are slow and expensive to train, and must be retrained to recognize new faces added to the set.  Older approaches which address these issues such as eigenfaces exist donÃ•t scale as they require a matrix decomposition. Apache Mahout offers a distributed singular value decomposition method, which scales to matrices of arbitrary sizes on Apache Spark, making it possible to use the older yet still powerful Eigenfaces approach to recognize and add new faces in near real time (with the help of Solr).   In this talk we present a full stack lambda-style facial recognition system. The offline component uses Apache Mahout to compute the eigenfaces. The online component identifies faces in an image with an interchangeable module, decomposes the face into a linear combination of the eigenfaces, searches for a matching face using SOLR, and if no match is found adds the face as a Ã’new faceÃ“.  ",https://youtu.be/wHBs_7VaScU,
2017,"Las Vegas, NV",Gary Sieling,Wingspan Technology,,Indexing Videos in Solr,Solr for Business,"FindLectures.com is a discovery engine for tech talks, historic speeches, and academic lectures. The site rates audio and video content for quality, showing different recommended talks each day on a variety of topics.   FindLectures.com crawls conference sites to get talk metadata, such as speaker names and bios, descriptions, and the date a video was recorded. Often these attributes are sparsely populated, or available across multiple websites. Additional attributes are inferred from audio and video content, but require more sophisticated data extraction to be useful in a text- oriented search engine like Solr.  This talk will discuss interesting lessons learned from crawling historical videos, demonstrate information extraction with machine learning, and show how to map real world problems to search engine functionality.",https://youtu.be/e_ia1DRz3l8,https://www.slideshare.net/lucidworks/indexing-videos-in-solr-gary-sieling-wingspan-technologies/edit?src=slideview&type=privacy
2017,"Las Vegas, NV",John Marquiss,Wolters Kluwer,,Doing Synonyms Right,Solr Feature Deep Dive,"This session will start with a presentation of the deprecated SynonymFilter and provide examples of its implementation and a discussion of its limitation with handling multi-word synonyms. We will then move on to an introduction of the new SynonymGraphFilter and present examples of its configuration and use, includind its handling of multi-word synonyms. Finally, we will introduce a Synonym-URI replacement strategy for multi-word synonyms and compare its index, query and linguistic performance to that of the SynonymGraphFilter.  After this session participants will be able:  	* Understand the differences between Index Time and Query Time synonym replacement 	* Understand the complexities regarding multi-word synonyms 	* Implement SynonymFiter based synonyms 	* Implement SynonymGraphFilter based synonyms 	* Implement a Synonym-URI replacement strategy",https://youtu.be/ouApjkJO2Qg,
2017,"Las Vegas, NV",Tom Burgmans ,Wolters Kluwer,,Art and Science come together when mastering Relevance Ranking,Solr Feature Deep Dive,"For most search based products, more relevant results mean a more valuable product. Getting this right is usually not something obvious. Within the world of Search, engineering relevance has become a profession in itself.  Solr comes out of the box with a scoring algorithm which is sophisticated but rarely good enough. Fortunately you can break it down and build it up again with different blocks.   This is a session where we demonstrate how to get an absolute grip on the relevance calculation of search results. We'll show the science of analyzing and manipulating the scoring algorithm and we'll show the art of shaping the score to your needs.",https://youtu.be/BsyVsmuS50c,https://www.slideshare.net/lucidworks/art-and-science-come-together-when-mastering-relevance-ranking-tom-burgmans-wolters-kluwer
2016,"Boston, MA",Trey Grainger,Lucidworks,,Reflected Intelligence: Lucene/Solr as a self-learning data system,Data Science,"What if your search engine could automatically tune its own domain-specific relevancy model? What if it could learn the important phrases and topics within your domain, automatically identify alternate spellings (synonyms, acronyms, and related phrases) and disambiguate multiple meanings of those phrases, learn the conceptual relationships embedded within your documents, and even use machine-learned ranking to discover the relative importance of different features and then automatically optimize its own ranking algorithms for your domain?In this presentation, you'll learn you how to do just that - to evolving Lucene/Solr implementations into self-learning data systems which are able to accept user queries, deliver relevance-ranked results, and automatically learn from your users' subsequent interactions to continually deliver a more relevant experience for each keyword, category, and group of users.Such a self-learning system leverages reflected intelligence to consistently improve its understanding of the content (documents and queries), the context of specific users, and the relevance signals present in the collective feedback from every prior user interaction with the system. Come learn how to move beyond manual relevancy tuning and toward a closed-loop system leveraging both the embedded meaning within your content and the wisdom of the crowds to automatically generate search relevancy algorithms optimized for your domain.",https://youtu.be/P65vdg8W1Rs?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/reflected-intelligence-lucenesolr-as-a-selflearning-data-system-presented-by-trey-grainger-lucidworks
2016,"Boston, MA",Cassandra Targett,Lucidworks,,Participating in the Community: Beyond Code,Exploring Solr,"So, you've learned a bit about how to use Solr, just enough to be dangerous (as they say), but you're not really a Java programmer. Can you still participate in the community? Absolutely!Much of the work we see going on in the Solr community is in the form of patches to the core codebase (or in contribs!), but any good open source community is larger than that. Good documentation, a professional website, a solid UI, and a strong base of users who help each other are all factors in a robust community.Even if you are not able to contribute patches, for whatever reason, there are many ways to participate and help keep Solr a strong search solution for many years to come. We'll walk through how to participate, and the skills you can bring to each opportunity.",https://youtu.be/NKNJXKsktes?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/participating-in-the-community-beyond-code-presented-by-cassandra-targett-lucidworks
2016,"Boston, MA",Chris Hostetter,Lucidworks,,Hidden Gems of Apache Solr,Exploring Solr,"Every day billions of documents are searched, sorted, faceted and highlighted by millions of users who have no idea that behind the scenes, Apache Solr is hard at work, making life simple for developers like you.  But what else can Solr do for you?In this session, we'll dive into some of the less well known, less understood, features of Apache Solr that even seasoned Solr developers may not be aware of -- features that can be useful in ways you might not have considered even if you do know about them, so you can take your Solr powered applications to the next level.",,
2016,"Boston, MA",Erik Hatcher,Lucidworks,,It's Just Search,Exploring Solr,"Think *inside* the box. Inside the *search* box, that is.The ""best""* search results incorporate many more factors than (just) textual matching and relevancy. Search experience owners manage query context _rules_, signals automatically feed back machine learned factors, users implicit and explicit behaviors filter and weight future interactions. Synergy emerges with several cooperating (just) searches.This talk will showcase and detail several (just) search examples including rules, typeahead/suggest, signals, and location awareness, bringing them all together into a cohesive search experience. ",https://youtu.be/3Zmhq54eCXU?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/its-just-search-presented-by-erik-hatcher-lucidworks
2016,"Boston, MA",Ishan Chattopadhyaya,Lucidworks,,State of Solr Security 2016,Exploring Solr,"Apache Solr has, over the past 1-2 years, developed lots of security related features. This talk focuses on exploring all features available to Solr users to help them secure their Solr installations, including authentication, authorization, storage level security, Zookeeper security, security against eavesdropping network packets, document level security, etc. This talk willll consist of simple examples of how to use these security features and also explore the current challenges users, esp. enterprise users, face in securing their Solr clusters, as well as future needs of the Solr users and the road ahead.",https://www.youtube.com/watch?v=dgiqhEYmlEs&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&index=37,https://www.slideshare.net/lucidworks/state-of-solr-security-2016-presented-by-ishan-chattopadhyaya-lucidworks
2016,"Boston, MA",Jake Mannix,Lucidworks,,Combining Content and Collaboration in Recommenders,Data Science,"Recommender Systems are typically built on two different types of training data: historical user-engagement, and the textual content of the items themselves (either descriptive text, tags, structured metadata, or the actual raw content of text items on their own).  This talk is an introductory overview of how to build a recommender system which uses both types of inputs to build a ""mixed-mode"" recommender, where you can parameterize (at request time, in some cases!) how much you want to rely on content, and how much on collaborative filtering.  We'll walk through building a horizontally scalable parameterized recommender service from just three components: Solr, Spark, and of course: training data.",https://youtu.be/c7fBs_dw6PA?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,
2016,"Boston, MA",Josh Ellinger,Lucidworks,,Building a Search UI with Lucidworks View,Ecosystem / Third-Party Apps,"Learn how to create a compelling branded search application with Lucidworks View. This session will be a tutorial on how to create a simple search UI, including the challenges that may be encountered.",https://youtu.be/IlnSRoqhS54?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/search-iu-and-lucidworks-view-presented-by-josh-ellinger-lucidworks
2016,"Boston, MA",Steve  Rowe,Lucidworks,,The Evolution of Lucene & Solr Numerics from Strings to Points,Exploring Solr,"Numeric representations in Lucene and Solr have evolved to be more efficient, performant, and capable as greater demands are made on indexes, from sorting, filtering and faceting to complex geo-spatial queries.  In this presentation I'll show how this evolution has impacted performance and resource usage, thereby enabling use cases that previously were better suited to other software.  The major focus will be on the multi-dimensional Points field support added in Lucene 6.0.",https://www.youtube.com/watch?v=2_CYR3CMUOU&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=11s&index=21,https://www.slideshare.net/lucidworks/the-evolution-of-lucene-solr-numerics-from-strings-to-points-presented-by-steve-rowe-lucidworks
2016,"Boston, MA",Timothy Potter,Lucidworks,,Your Big Data Stack is Too Big,Data Science,"While technologies such as Spark, Hadoop, and Solr have come a long way over the past couple of years, companies continue to struggle to convert all this innovation into successful business outcomes. Too often, big data projects run over budget and fail to deliver ROI. Instead, companies are left with a bloated stack of complex technologies that are cumbersome to maintain and are slow to adapt to new business requirements. Once the consultants have left the building, the big data platform fails to keep up with demands for better access to larger and more complex enterprise data sets.In this talk, Tim presents a better way to go about big data analytics using Lucidworks Fusion. Attendees will come away with actionable insights to solving common big data problems such as scaling data ingest from any source, providing both full-text search and SQL query capabilities for the same data set, and leveraging machine learning. The goal of this talk is to parse through the hype of big data and show how a lean, tightly integrated stack built on Solr and Spark provides all you need to do big data right.",https://www.youtube.com/watch?v=mqepJUiqmd4&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=30s&index=23,https://www.slideshare.net/lucidworks/your-big-data-stack-is-too-big-presented-by-timothy-potter-lucidworks
2016,"Boston, MA",Nery  Encarnacion Padro,Allstate Insurance company,,The path to universal search,Use Case,"Too many search boxes? You don't remember which one to use? You know the document you are looking for exists, but you just can't find it.  Come join us to get an understanding on how Lucidworks Fusion helped Allstate traverse disparate data sources and consolidate scattered search boxes to create a better user experience.  ",https://youtu.be/XB97lnx0Qtg?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,
2016,"Boston, MA",Kevin Risden,"Avalon Consulting, LLC",,Solr JDBC,Exploring Solr,"One of the new features of Solr 6 is a JDBC driver that can be hooked up to various SQL clients and database visualization tools. Solr JDBC opens up a whole new set of use cases and lowers the barrier to entry for many users. I'll highlight the Solr JDBC feature, explain some use cases, and demonstrate connecting SQL clients. You will learn how Solr JDBC can unlock more potential from your Solr environment.",https://youtu.be/XpWomATSKzM?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/solr-jdbc-presented-by-kevin-risden-avalon-consulting
2016,"Boston, MA",Timothy Rodriguez,Bloomberg,,Solr Highlighting at Full Speed,Use Case,"Searching over a large corpus of legal documents brings about a number of unique challenges in search.  In legal search, recall matters.  Users often enter broad queries and leverage digests to help them determine the relevancy of a result before committing to reading a long document.  This has made highlighting quality and speed with minimal memory use a key requirement for Bloomberg Law.  In this talk, attendees will learn about Bloomberg Law's efforts to improve highlighting performance dramatically via the introduction of a new highlighter for Solr that uses your index to the best of its advantage.",https://youtu.be/tv5qKDKW8kk?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/solr-highlighting-at-full-speed-presented-by-timothy-rodriguez-bloomberg-david-smiley-d-w-smiley-llc
2016,"Boston, MA",Dennis Gove,Bloomberg LP,,Creating New Streaming Expressions,Exploring Solr,"Streaming Expressions can be used in a wide range of applications from order tracking to bioinformatics. They can be used to do massively parallel processing across huge datasets or simple joins between sharded collections. They can be used to update collections or alert when certain documents are seen. And streaming expressions are fully extensible. In this talk, attendees will learn the ins and outs of creating new Stream classes and how to make use of those in their own searches. We'll cover the differences between stream sources and stream decorators. We'll discuss the minimum set of functionality a stream must provide. And we'll see how to add new streaming classes to your collections' configurations. In the end, attendees will see how simple it is to create and use new Streaming classes.",https://youtu.be/YyAgTWGX9nE?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/creating-new-streams-presented-by-dennis-gove-bloomberg-lp
2016,"Boston, MA",Steven Bower,Bloomberg LP,,Building a Vibrant Search Ecosystem at Bloomberg,Use Case,"Search is a core technology that allows Bloomberg to deliver financial news and information quickly and reliably to our clients. The Search Infrastructure team has created a high performance, stable and scalable search ecosystem to support a large, complex and diverse set of search applications. Providing search as a service to the thousands of developers in this demanding environment required us to take a holistic approach. In this talk we'll discuss both the organizational and technical challenges we've encountered and the approach we've taken to solve them. We'll dive into the details of our platform; from the way we engage with our tenants, interact with the Solr community, to the infrastructure and tools we use to manage, monitor and scale our platform.",https://youtu.be/0Y00-_NEIFk?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/building-a-vibrant-search-ecosystem-bloomberg-presented-by-steven-bower-ken-laporte-bloomberg
2016,"Boston, MA",Nitin Sharma,BloomReach,,Rebalance API for SolrCloud,Ecosystem / Third-Party Apps,"SolrCloud with large data sets and collections usually run into unevenly balanced clusters. This causes skewed data and replica distribution across SolrCloud nodes.  Automatic Node Discovery  in an existing cluster does not  cause data to be re-distributed. Dynamically scaling up or scaling down collections based on index/config size or cluster size is non trivial and poses operational overhead.  Rebalance API offers a  flexible way of redistributing data in SolrCloud while guaranteeing zero downtime. It offers multiple scaling strategies that aid in smarter/faster index manipulation and multiple allocation strategies that offer smarter collection placement in the cluster.  It also offers a platform for users to write their own scaling strategy as they see fit. The api has been built in an open source friendly fashion.",https://youtu.be/MfoVxHxyxSM?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/rebalance-api-for-solrcloud-presented-by-nitin-sharma-netflix-suruchi-shah-bloomreach
2016,"Boston, MA",Mark Miller,Cloudera,,SolrCloud: High Availability and Fault Tolerance,Exploring Solr,"Committer Mark Miller will discuss the current SolrCloud architecture for handling disaster and recovery. This talk will cover how SolrCloud was designed to protect your data in the face of failure, some of the growing pains the system has gone through, and what is left to do in the near future when it comes to fault tolerance and recovery. Learn about the low level details that help keep your data safe as well as what choices and decisions you should make as a SolrCloud user that cares about data integrity.",https://youtu.be/dedxOZNqCig?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/solrcloud-high-availability-and-fault-tolerance-presented-by-mark-miller-cloudera
2016,"Boston, MA",Mike Drob,Cloudera,,Why is my Solr slow?! (An HTrace Case Study),Ecosystem / Third-Party Apps,"Attempting to diagnose distributed system slowness can be one of the most challenging and headache inducing activities for an operations team. Armed with a suite of low level metrics and host monitoring, the first and only option often available is a lengthy process of elimination of each component in the hardware and software stack.In this session we will learn how to instrument Solr to send distributed tracing data to HTrace. We will then look at some sample traces and learn how to identify slowness in different parts of the entire stack, looking for trends and outliers in the Solr operation. We will complete the session by discussing how to add tracing to your existing client applications for true end-to-end visibility into the performance of your cluster.",https://youtu.be/emv8UmuCeY4?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/why-is-my-solr-slow-presented-by-mike-drob-cloudera
2016,"Boston, MA",Yonik Seeley,Cloudera,,Parallel SQL and Analytics with Solr,Data Science,"Analytics has increasingly become a major focus for Apache Solr, the primary search engine in the Hadoop stack.  This talk will cover recent Solr developments in the areas of faceting and analytics, including parallel SQL, streaming expressions, distributed join, and distributed graph queries.  Given the increasing number of APIs and techniques that can be brought to bear, we'll also cover which approach should be preferred in different situations, including how to maximize scalability.",https://youtu.be/ZZR4BdmuAhs?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/parallel-sql-and-analytics-with-solr-presented-by-yonik-seeley-cloudera
2016,"Boston, MA",David Smiley,D W Smiley LLC,,HHypermap: Heatmap Analytics of a Billion Tweets,Use Case,"The Harvard Center for Geographic Analysis has established the HHypermap (Harvard Hypermap) system, comprised of multiple open-source projects aimed at searching vast amounts of spatial data.  This talk centers on a system based on SolrCloud that can do realtime search on a billion Twitter tweets with heatmap analytics of sentiment analysis. The open-source system is designed to be suitable for social media data sets or sensor data.Harvard CGA commissioned Apache Lucene/Solr's heatmap faceting capability in 2015 and this work now continues in 2016. The first new part is computing numeric stats per cell (not just doc counts), which can be used for a variety of applications.  The second part is improving Lucene's grid cell indexing scheme to cater to heatmaps, thus allowing heatmap generation to be very fast for large data sets. This talk discusses the system design/architecture as well as the spatial details on how Lucene/Solr was improved.",https://youtu.be/nzAH5QEl9hQ?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/hhypermap-heatmap-analytics-at-scale-presented-by-david-smiley-d-w-smiley-llc
2016,"Boston, MA",Simon Hughes,Dice.com,,Evolving the Optimal Relevancy Scoring Model at Dice.com,Data Science,"A popular conference topic in recent years is using machine learned ranking (MLR) to re-rank the top results of a Solr query to improve relevancy. However, such approaches fail to first ensure that they have the optimal query configuration for their search engine, without which the re-ranked results may fail to contain the most relevant items for each query (lowering recall). Solr offers many configuration options to control how documents are ranked and scored in terms of relevancy to a user's query, including what boosts to assign to each field, and how strongly to boost phrasal matches. It is common for companies to manually tune these parameters to optimize relevancy, but this process is highly subjective and not guaranteed to produce the optimal results. We will show a data-driven approach to relevancy tuning that uses optimization algorithms, such as evolutionary algorithms, to evolve a query configuration that optimizes the relevancy of the results returned using data captured from our query logs. We will also discuss how we experimented with evolving a custom similarity algorithm to out-perform BM25 and tf.idf similarity on our dataset. Finally, we'll discuss the dangers of positive feedback loops when training machine learned ranking models.",https://youtu.be/z4c1xU7arhc?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/evolving-the-optimal-relevancy-scoring-model-at-dicecom-presented-by-simon-hughes-dicecom
2016,"Boston, MA",James Strassburg,Direct Supply,,Building a Solr Continuous Delivery Pipeline With Jenkins,Ecosystem / Third-Party Apps,"In this session, I will demonstrate how to build a secure continuous delivery pipeline for Solr using Jenkins and various Jenkins plugins using the installation scripts that are packaged with Solr. I'll cover how to (optionally) build Solr and deploy it using Solr's own scripts and why one might want to do this. I'll cover the fundamentals of continuous delivery and what a CD pipeline looks like using Jenkins plugins.  Finally, I'll will discuss the files comprising the Solr configuration that should be version controlled separately from Solr itself and how to configure various environments using core properties.",https://youtu.be/OR8BQl1UfMg?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/building-a-solr-continuous-delivery-pipeline-with-jenkins-presented-by-james-strassburg-direct-supply
2016,"Boston, MA",Charlie Hull,Flax,,"Coffee, Danish & Search: How to build a Solr-powered news search engine",Use Case,"We'll show how we have worked with Denmark's leading media analysis company on a successful project to migrate their entire search framework from Autonomy IDOL & Verity to one based on Solr Cloud and our own Luwak stored search library, itself based on Lucene. We'll describe how we helped the client translate thousands of existing queries to their own query language; enhanced Solr wildcard search performance; built custom highlighting; extended Solr logging and developed a framework to handle multiple languages (including one spoken by only 66,000 people). We'll show how the migration achieved practically zero negative change in precision/recall and how the continuing partnership with our client enables further feature development as necessary.",https://youtu.be/NrDOrLn_59c?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/coffee-danish-search-presented-by-alan-woodward-charlie-hull-flax
2016,"Boston, MA",Scott Blum,"FullStory, Inc",,Large Scale Solr at FullStory,Use Case,"Come see how we're using Solr to make search FullStory's central feature.  Learn about some of the problems we've run into scaling up a large Solr cluster at FullStory, and how we've solved them. And finally, I'll briefly introduce Solrman, the open source service we've released that monitors a Solr cluster and automatically optimizes how data is distributed across a Solr cluster.",https://youtu.be/8L80ABTedj4?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/large-scale-solr-at-fullstory-presented-by-scott-blum-fullstory
2016,"Boston, MA",Shai Erera,IBM,,Building and running a Solr-as-a-Service for IBM Watson,Use Case,"Running a managed Solr service brings fun challenges with it, to both the users and the service itself. Users typically do not have access to all components of the Solr system (e.g. the ZK ensemble, the actual nodes that Solr runs on etc.). On the other hand the service must ensure high-availability at all times, and handle what is often user-driven tasks such as version upgrades, taking nodes offline for maintenance and more.In this talk I will describe how we tackle these challenges to build a managed Solr service on the cloud, which currently hosts few thousands of Solr clusters. I will focus on the infrastructure that we chose to run the Solr clusters on, as well how we ensure high-availability, cluster balancing and version upgrades. ",https://youtu.be/ZMoQGoyrMq0?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/building-and-running-solrasaservice-presented-by-shai-erera-ibm
2016,"Boston, MA",Anshum Gupta,IBM Watson,,Working with deeply nested documents in SolrCloud,Data Science,"Until recently, Solr did not support deeply nested documents, but that has changed over the past few releases. While still not a popular use-case, Solr can now be used to handle deeply nested documents to perform search and faceting on them, like nested email threads, comments and replies on social media etc.This talk would cover pointers around pre-processing of data so that it can not only be consumed by Solr but also make it possible to perform complex search and statistical aggregations on top of it. It would also cover query formation for sample use cases of nested data and multiple options and features that Solr provides for faceting or aggregation of the documents. By the end of this talk, Solr users would have a better understanding of both the features that Solr provides and how to work with them to find answers to interesting questions from deeply nested documents and the limitations that currently exist and how to work around to accomplish tasks indirectly.",https://www.youtube.com/watch?v=qV0fIg-LGBE&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=7s&index=13,https://www.slideshare.net/lucidworks/working-with-deeply-nested-documents-in-apache-solr-presented-by-anshum-gupta-alisa-zhila-ibm-watson
2016,"Boston, MA",Adam Williams,Iron Mountain,,Cross Data Center Replication for the Enterprise,Exploring Solr,"This presentation is meant to explore the use of cross data center replication, now available in Solr 6, to show a real-world example running in production.  Iron Mountain has now been running cross data center replication (CDCR) for over a year.  We have over 100,000 users and indexes supporting 26 clouds (5 billion documents) with rapid/continuous indexing.  We rely on cross data center replication for disaster recovery and backups.  This allows us to maintain a 'hot' standby environment for failover.  We spent considerable effort performance testing and tuning CDCR as well as determining the hardware / storage required to support the system.  There are some gotchas that need to be considered, such as the amount of disk space to allow for backups, network performance, adjusting configurations and monitoring.  CDCR works much like mirroring approaches for databases, yet there are some distinct differences in how this works for Solr.  The implementation of CDCR was performed by several committers which Iron Mountain engaged to develop the capability.   Representatives from the team will speak to the technical approach CDCR uses, the CdcrRequestHandler and versioning approach used.  Lastly, we will cover some possible future enhancements for CDCR, including improving throughput and extending the current code base to support active/active replication between multiple data centers.",https://youtu.be/fAvO8bHTh-Q?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/cross-data-center-replication-for-the-enterprise-presented-by-adam-williams-iron-mountain
2016,"Boston, MA",Kerry Koitzsch,Kildane Software Technologies Inc,,Using Apache Solr for Images As Big Data: A Case Study,Use Case,"Images as big data' is an especially interesting topic in the era of high-performance systems based on Solr, Hadoop, and Apache Spark. Machine learning and image analysis packages are readily available to apply to this problem, and high quality industrial applications may be built from off-the-shelf third party components. In this talk, we will discuss a case study based on an 'image as big data' analytical system --- the  Image as Big Data Toolkit (IABDT). IABDT uses Lucene, distributed Lucene, Solr, and Hadoop as key component technologies. We will present examples of IABDT in action, using Solr as a key search technology in its implementation, show a medical image case study, and discuss future work and extensions of the IABDT system.",https://www.youtube.com/watch?v=pFAPxbPDbtE&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&index=19,https://www.slideshare.net/lucidworks/using-apache-solr-for-images-as-big-data-presented-by-kerry-koitzsch-wipro-technologies
2016,"Boston, MA",Kevin Watters,KMW Technology,,Solr Graph Query,Exploring Solr,"This is an overview of the new Solr Graph Query.  We will discuss the semantics of this new query operator in Lucene/Solr and how it can be used to solve real world knowledge graph problems.  We will discuss how to handle data that is a graph in nature and cover items such as social networking search, recommendation engines, security filtering, and how to use knowledge graphs and ontologies to draw conclusions, all using the Solr Graph query.",https://www.youtube.com/watch?v=83c6GBaE1TE&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&index=20,https://www.slideshare.net/lucidworks/solr-graph-query-presented-by-kevin-watters-kmw-technology
2016,"Boston, MA",Gaurav Kapila,Microsoft Corporation,,Microsoft use of SOLR to deliver multitenant Log Analytics SAAS service,Ecosystem / Third-Party Apps,"We will present architecture of Search service backing Microsoft Operations Management Suite's Log Analytics Solution. With Microsoft Operations Management Suite, you can now empower operations teams to effortlessly collect, store and analyze log data from virtually any Windows Server and Linux source-regardless of volume, format or location. Separate the signal from the noise with simple, powerful log management tools and access real-time operational intelligence with improved troubleshooting, operational visibility and fast search to explore, investigate and fix incidents quickly.Join us as we share our experience and learnings in resolving issues all over the spectrum like scalability, COGS, compliance requirements, customer data isolation, data persistence, query response streaming. Learn what it takes to run SOLR on commodity hardware as well over scaled up architecture.",https://www.youtube.com/watch?v=JhEbBAXLy4M&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&index=29,https://www.slideshare.net/lucidworks/multitenant-log-analytics-saas-service-using-solr-presented-by-chirag-gupta-srivatsan-parthasarathy-microsoft
2016,"Boston, MA",Ivan Provalov,Netflix,,Autocomplete Multi-Language Search Using Ngram and EDismax Phrase Queries,Exploring Solr,"Autocomplete presents some challenges for search in that users' search intent must be matched from incomplete token queries.  Many non-Latin character based languages have additional complications.  The following are some of the examples of unique language-specific issues which must be addressed in search systems in order to support these languages:  - Japanese and Chinese multiple scripts (Hiragana, Katakana, Romaji, Zhuyin, Paoding)- No token-delimiters for Japanese and Chinese- Korean character composition- Arabic spelling variations of the transliterated foreign wordsI will talk about these challenges in detail, describe our approaches to solving them, and share some tools (queries testing framework) we used to help addressing these issues.",https://www.youtube.com/watch?v=Kj8jtih3x6w&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=63s&index=36,https://www.slideshare.net/lucidworks/autocomplete-multilanguage-search-using-ngram-and-edismax-phrase-queries-presented-by-ivan-provalov-netflix
2016,"Boston, MA",Doug Turnbull,OpenSource Connections,,Anyone Can Build a Recommendation Engine with Solr,Exploring Solr,"You don't need a PhD to get started with recommenders! You just need Solr! In this talk, you'll get several examples of building different recommendation strategies on top of Solr. You'll see how to deliver recommendations using user behavior, and how to combine that with content-specific signals. We'll cover- Folks who purchased this products also purchased- Personalized recommendations based on past browsing history- How Solr makes tuning relevance and scaling straight-forwardWe'll also touch on many of the classic problems with recommenders, including the cold start problem and the Oprah Book Club problem. Come if you've got some Solr experience and would like to learn to build a recommender!",https://youtu.be/ZoTfTDAwEkY?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/anyone-can-build-a-recommendation-engine-with-solr-presented-by-doug-turnbull-opensource-connections
2016,"Boston, MA",Josef Adersberger,QAware,,Time Series Processing with Solr and Spark,Ecosystem / Third-Party Apps,"A lot of data is best represented as time series: Operational data, financial data, and even in data warehouses the dominant dimension is often time. We present Chronix, a time series database based on Apache Solr and Spark which is able to handle trillions of time series data points and perform interactive queries. Chronix Spark is open source software and battle-proven at a German car manufacturer and an international telco. We demonstrate several use cases of Chronix from real-life. Afterwards we lift the curtain and deep-dive into the Chronix architecture esp. how we're using Solr to store time series data and how we've hooked up Solr with Spark. We provide some benchmarks showing how Chronix has outperformed other time series databases in both performance and storage-efficiency. Chronix is open source under the Apache License (http://chronix.io).",https://youtu.be/UVrOWhMEEf8?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/time-series-processing-with-solr-and-spark-presented-by-josef-adersberger-qaware
2016,"Boston, MA",Johannes Weigend,QAware GmbH,,Leveraging the power of SOLR with SPARK,Data Science,Solr is a distributed NoSQL database with impressive search capabilities. Spark is the new megastar in the distributed computing universe. In this code-intense session we show you how to combine both to solve real-time search and processing problems. We will show you how to set up a Solr/Spark combination from scratch and develop first jobs with runs distributed on shared Solr data. We will also show you how to use this combination for your next-generation BI platform.,https://www.youtube.com/watch?v=jOvBsmCRFOM&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=17s&index=14,https://www.slideshare.net/lucidworks/leveraging-the-power-of-solr-with-spark-presented-by-johannes-weigend-qaware
2016,"Boston, MA",Mario-Leander Reimer,QAware GmbH,,Automotive Information Research driven by Apache Solr,Use Case,We are searching the unknown. How can you find hidden and unknown relationships in unrelated relational data silos? How can you search the relevant information in a 10^56 dimensional space? How do you create a consistent yet up-to-date information network for over 20 languages on a daily basis? And how on earth do you convice IT governance to let you use Solr for this kind of job? All this sound impossible? This talk will give the answers and present a detailed case study and success story about how we used Apache Solr to build a search based business intelligence and automotive information research application for a major German car manufacturer.,https://www.youtube.com/watch?v=eA5x48gIsY4&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=20s&index=30,https://www.slideshare.net/lucidworks/automotive-information-research-driven-by-apache-solr-presented-by-marioleander-reimer-qaware
2016,"Boston, MA",Ammar Harris,Salesforce,,Customizing Ranking Models in Solr to improve relevance for Enterprise Search,Use Case,"Solr provides a suite of built-in capabilities that offers a wide variety of relevance related parameter tuning. Index and/or query time boosts along with function queries can provide a great way to tweak various relevance related parameters to help improve the search results ranking. In the enterprise space however, given the diversity of customers and documents, there is a much greater need to be able to have more control over the ranking models and be able to run multiple custom ranking models.At Salesforce, we have a multi-level ranking pipeline, first ranker (L1), is the basic lucene scoring based on tf-idf and the second ranker (L2), implements more complex ranking models ranging from something as trivial as a linear regression to the more complex models such as a boosted decision tree. This L2 ranker inside Solr enables us to extract features for every document from within the Solr Index and leverage them during ranking model execution. This talk discusses the motivation behind creating an L2 ranker and the use of Solr Search Component for running different types of ranking models.",https://youtu.be/IApmPhm_R_U?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/customizing-ranking-models-for-enterprise-search-presented-by-ammar-haris-joe-zeimen-salesforce
2016,"Boston, MA",Jayesh Govindarajan,Salesforce,,Improving Enterprise find-ability with custom relevance models,Data Science," On the surface search on the web and within the enterprise share some common characteristics. However, there are key differences that makes enterprise search a specialized domain. For each of Salesforce's 150,000 customers, we enable search over highly diverse and custom data sets spanning 3 distinct forms -- CRM data in relational systems, unstructured data in content management systems and enterprise social data.This talk shares some of the insights we've gleaned from building a relevance engine for the enterprise from the ground up. Specifically, we lay out the components that enable us to machine learn our ranking function from training to evaluation. We showcase the customizations applied on various boosts and query functions provided by Solr based on data type being searched for. Finally, we touch upon some of the metrics that are used to measure and optimize search relevance by document type. ",https://www.youtube.com/watch?v=_afpT6Oz5Xs&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=1282s&index=32,https://www.slideshare.net/lucidworks/improving-enterprise-findability-presented-by-jayesh-govindarajan-salesforce
2016,"Boston, MA",Alexandre Rafalovitch,Search Stack Solutions,,Rebuilding Solr 6 examples - layer by layer,Exploring Solr,"Did you know that Solr 6 ships with 10! different examples? Do you know where they are and how to best learn from each one of them? This session will do a quick yet thorough explanation of all the shipped examples. Then, we will take one of the examples and rebuild it from a basic schema up, so you understand how it ticks. At the end, you will know how to read the examples that ship with Solr and how to transfer relevant parts of those examples to your own schema and configuration.",https://www.youtube.com/watch?v=lc6krl8iC9o&list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm&t=6s&index=57,https://www.slideshare.net/lucidworks/rebuilding-solr-6-examples-layer-by-layer-presented-by-alexandre-rafalovitch-search-stack-solutions
2016,"Boston, MA",Paul Nelson,Search Technologies,,Searching the Enterprise Data Lake with Solr - Watch us do it!,Data Science,"People talk a lot about building enterprise 'data lakes'or data hubs to knock down data silos and democratize data access to different types of users.  These are abstract topics. Maybe it's time to stop talking and see, practically, how this can be done!We are currently processing and searching data from 'data lake' for a large life sciences customer and in this demo we'll show you, step by step, how this is accomplished. We'll take disparate data sources like document files and data tables; we'll show how these records can be combined, processed, prepared and indexed; and then we'll show search and visualizations on this content to provide business insight into this 'data lake'. All of this will be done with Solr Cloud.",https://youtu.be/fTARkRyDR-c?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/searching-the-enterprise-data-lake-with-solr-watch-us-do-it-presented-by-paul-nelson-search-technologies
2016,"Boston, MA",Rafal Kuc,Sematext Group,,How to run Solr on Docker. And why.,Ecosystem / Third-Party Apps,"Docker is all the rage these days.  While one doesn't hear much about Solr on Docker, we're here to tell you not only that it can be done, but also share how it's done.We'll quickly go over the basic Docker ideas - containers are lighter than VMs, they solve ""but it worked on my laptop"" issues - so we can dive into the specifics of running Solr on Docker.  We'll do a live demo showing you how to run Solr master - slave as well as SolrCloud using containers, how to manage CPU assignments, constraint memory and use Docker data volumes when running Solr in containers. We will also show you how to create your own containers with custom configurations. Finally, we'll address one of the core Solr questions - which deployment type should I use? We will demonstrate performance differences between the following deployment types:- Single Solr instance running on a bare metal machine - Multiple Solr instances running on a single bare metal machine- Solr running in containers - Solr running on virtual machine- Solr running on virtual machine using unikernelFor each deployment type weÃ_Ã_Â»ll address how it impacts performance, operational flexibility and all other key pros and cons you ought to keep in mind.",https://youtu.be/42vw3KxWnfg?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,
2016,"Boston, MA",Radu Gheorghe,"Sematext Group, Inc.",,Tuning Solr and its Pipeline for Logs,Ecosystem / Third-Party Apps,"This is an updated talk about how to use Solr for logs and other time-series data, like metrics and social media. In 2016, Solr, its ecosystem, and the operating systems it runs on have evolved quite a lot, so we can now show new techniques to scale and new knobs to tune.We'll start by looking at how to scale SolrCloud through a hybrid approach using a combination of time- and size-based indices, and also how to divide the cluster in tiers in order to handle the potentially spiky load in real-time. Then, we'll look at tuning individual nodes. We'll cover everything from commits, buffers, merge policies and doc values to OS settings like disk scheduler, SSD caching, and huge pages.Finally, we'll take a look at the pipeline of getting the logs to Solr and how to make it fast and reliable: where should buffers live, which protocols to use, where should the heavy processing be done (like parsing unstructured data), and which tools from the ecosystem can help.",https://youtu.be/1gzwAgrk47c?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/tuning-solr-and-its-pipeline-for-logs-presented-by-rafa-ku-radu-gheorghe-sematext
2016,"Boston, MA",Alexander Filipchik,Sony Interactive Entertainment,,PlayStation and Lucene: Indexing 1 Million documents per second on 18 servers,Use Case,"What if I tell you that PlayStation4 is a not just a gaming console? What if I tell you that PlayStation Network is a system that handles more than 70 millions active users? What if I tell you, that in order to create an awesome gaming experience we support a personalized search at scale? And finally, what if I tell you, that one of the systems that provides this personilized expirience currently indexes up to 1 Million documents per second using Lucene and only uses 18 mid sized Amazon instances?Intrigued? Join the talk to learn how it is possible!",https://youtu.be/mZMYwxZ2rwg?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/playstation-and-lucene-indexing-1m-documents-per-second-presented-by-alexander-filipchik-sony-interactive-entertainment
2016,"Boston, MA",Howard Wan,Target Inc,,Using a Query Classifier to dynamically boost Solr ranking,Data Science,"About 40% of our queries are ambiguous, which can result with products  from many categories. For example, the query ""red apple"" can match the following products:1. red apple ipod (electronic category)2. red apple fruit ( fresh produce )3. red apple iphone case ( accessories)It is desirable to have a classifier to instruct Solr to boost items from the desire category. In addition, for a search engine with small index, a good percentage of the queries may have little or no results. Is it possible to use the classifier to solve both problems?This talk discusses a classifier built from behavior data which can dynamically re-classify the query to solve both problems.",https://youtu.be/ek3ftFfhnWE?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,
2016,"Boston, MA",Rongkai Zhao,The Home Depot,,Challenges of e-commerce product search and the case study of the Home Depot enterprise search,Use Case,"In this talk, three independent but connected topics are discussed. On top of the baseline Solr and Fusion engine, how the Home Depot extends Solr to solve their unique business rule requirements, implement intelligent type-ahead system, and tune search relevancy in a scientific way instead of using black magic. Along with many other unique solutions, The Home Depot established their enterprise search engine using Solr.The Home Depot used to be one of the biggest Endeca customers. While developing extensions to the Endeca system, this proprietary system become more and more a barrier to the ever increasing business demands. Solr and Fusion offered flexibility and certain amount of out-of-box functionalities, it is still not sufficient and therefore the Home Depot search and personalization team challenged themselves to come up with a comprehensive solution. This talk provides a case study in hoping the audiences can benefit from the material to expand their search engine to the next level.",,
2016,"Boston, MA",Stefan Olafsson,Twigkit,,Build a great application in minutes,Ecosystem / Third-Party Apps,Talk about the importance of user experience in the context of search applications. Why UX should not be left till last. How use of search technologies like Solr has undergone a paradigm shift from simple keyword search to advanced analytics and discovery. Show how an application that works on mobile devices and  meets these requirements can be built in minutes.,https://youtu.be/bkN6IMrc2H4?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/build-a-great-application-in-minutes-presented-by-stefan-olafsson-twigkit
2016,"Boston, MA",Dion Olsthoorn,Wolters Kluwer,,Loading 350M documents into a large Solr cluster in 8 hours or less,Use Case,"This session is a Case Study that shows you how a large set of xml documents can be loaded into a multi-collection Solr cluster in a fast, efficient and controlled way. The presenter will show how Solr is used within his organization and then explains how his team started out with loading content into their SolrCloud using the standard post.jar tool, which has some concealed limitations. You will see how this led to their current solution that exists of multiple cloud-aware ""content posting"" worker-processes, controlled by a clever master-less queuing system in ZooKeeper. Also, the presenter will cover how to load content into a busy Solr cluster, without affecting the response times of running queries too much.",https://youtu.be/07Jpl-QJ27k?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,https://www.slideshare.net/lucidworks/loading-350m-documents-into-a-large-solr-cluster-presented-by-dion-olsthoorn-wolters-kluwer
2016,"Boston, MA",Dragan Milosevic,Zanox AG,,"Aggregations: Solrcloud/Elasticsearch, Droid or Hbase",Ecosystem / Third-Party Apps,"You need to build a highly scalable system for executing aggregation-queries in real-time on big-data. But you do not have several weeks to try each and every available technology that supports such queries and you are not sure which one to pick. We have taken time to build fully functional prototypes and have learned important lessons that can serve as precious time-saving guidelines while deciding about the architecture of your system.To have an unbiased comparison, we installed each built prototype on a cluster of machines having exactly the same hardware configuration. We estimated the ingestion performance by measuring the time that each prototype needs in order to make the imported records become available for querying. We executed real-user aggregation-queries to measure the response time while simulating various ingestion loads. By increasing the number of machines that are used to run the built prototypes, we were able to estimate the ability of each technology to scale. Finally as a bonus, we will also share our subjective opinion regarding the easiness to use, flexibility, customizability and available community support for each evaluated technology.",https://youtu.be/p0WZHm5yUMQ?list=PLU6n9Voqu_1F1Skr8qlaO8_VtF4D8JEhm,
2015,"Austin, TX",Trey Grainger,CareerBuilder,"Trey Grainger is the Director of Engineering over Search & Recommendations at CareerBuilder.com and is the co-author of Solr in Action (2014, Manning Publications), the comprehensive example-driven guide to Apache Solr. His search experience includes handling multi-lingual content across dozens of markets/languages, machine learning, semantic search, big data analytics, customized Lucene/Solr scoring models, data mining, and recommendation systems. Trey is also an advisor to several startups, is the Founder of Celiaccess.com, a gluten-free search engine, and is a frequent speaker on topic related to open source search, information retrieval, and recommendation systems.",Leveraging Lucene/Solr as a knowledge graph and intent engine,,"Search engines frequently miss the mark when it comes to understanding user intent. For example, if a user types in (senior java developer portland, or hadoop), you or I know that the term ""senior"" designates an experience level, that ""java developer"" is a job title related to ""software engineering"", that ""portland, or"" is a city with a specific geographical boundary, and that ""hadoop"" is a technology related to terms like ""hbase"", ""hive"", and ""map/reduce"". Out of the box, however, most search engines just parse this query as text:((senior AND java AND developer AND portland) OR (hadoop)), which is not at all what the user intended. This talk will describe how you can leverage Lucene/Solr to power a knowledge graph that can extract phrases, understand and weight the semantic relationships between those phrases and known entities, and expand the query to include those additional conceptual relationships. We will discuss how to train the search engine to parse the query into this intended understanding, and how to reflect this understanding to the end user to provide an insightful, augmented search experience. Buzzwords: Semantic Search, Finite State Transducers, Probabilistic Parsing, Bayes Theorem, Augmented Search, recommendations, nlp, knowledge graphs",https://www.youtube.com/watch?v=CZQ2l5fzQjs&index=10&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/leveraging-lucenesolr-as-a-knowledge-graph-and-intent-engine-presented-by-trey-grainger-careerbuilder
2015,"Austin, TX",Grant Ingersoll,Lucidworks,"Grant is the CTO and co-founder of LucidWorks as well as an active member of the Apache Lucene community Ã_Ã_Ã± a Lucene and Solr committer, and co-founder of the Apache Mahout machine learning project. He is also the lead author of ""Taming Text"" from Manning Publications.  GrantÃ_Ã_Â»s experience includes engineering a variety of search, question answering and natural language processing applications for a variety of domains and languages. Grant earned his bachelor degree from Amherst College in Math and Computer Science and his master degree in Computer Science from Syracuse University.",Searching for Better Code,Innovation,"They say when you are a hammer, everything looks like a nail.  I guess when you are a search vendor, everything looks like search, including writing code, or at least helping improve the code one writes.  At Lucidworks, we leverage Solr and Lucidworks Fusion internally to do a lot of things to improve our organization, ranging from support to sales and engineering.  This talk will detail how we leverage Fusion's connectors (Github, Subversion, JIRA), pipelines, dashboards and search capabilities to produce higher quality code and products across the organization. Using live demos, we'll start with simple code search and quickly move on to demonstrate how to use Fusion and Solr for code reviews, engineering metrics, quality assurance, IT operations, and more.",https://youtu.be/7J2QrDExUr8?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/searching-for-better-code-presented-by-grant-ingersoll-lucidworks
2015,"Austin, TX",Kiran Chitturi,Lucidworks,,Event processing and data analytics with Lucidworks Fusion,,"Event processing is a common need in e-commerce systems (views, conversions, cart analysis, click-throughs, reviews, system logs, etc), but there are many challenges faced in processing, analyzing and using such event streams to enhance the business metrics. I will present how Lucidworks Fusion uses Solr and Spark to support event stream collection, doing simple and complex aggregations at scale, and doing other data analytic tasks using the platform. I will illustrate this with an example recommender system and a Ã±related entitiesÃ® graph navigation.",https://youtu.be/TbQvogD0vFE?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/events-processing-and-data-analysis-with-lucidworks-fusion-presented-by-kiran-chitturi-lucidworks
2015,"Austin, TX",Timothy Potter,Lucidworks,"Timothy Potter is a senior member of the engineering team at Lucidworks and a committer on the Apache Solr project. Tim focuses on scalability and hardening the distributed features in Solr. Previously, Tim was an architect on the Big Data team at Dachis Group, where he worked on large-scale machine learning, text mining, and social network analysis problems using Hadoop, Cassandra, and Storm. Tim is the co-author of Solr In Action",Solr and Spark for Real-Time Big Data Analytics,Data Science,"Apache Solr has been adopted by all major Hadoop platform vendors because of its ability to scale horizontally to meet even the most demanding big data search problems. Apache Spark has emerged as the leading platform for real-time big data analytics and machine learning. In this presentation, Timothy Potter presents several common use cases for integrating Solr and Spark.Specifically, Tim covers how to populate Solr from a Spark streaming job as well as how to expose the results of any Solr query as an RDD. The Solr RDD makes efficient use of deep paging cursors and SolrCloud sharding to maximize parallel computation in Spark. After covering basic use cases, Tim digs a little deeper to show how to use MLLib to enrich documents before indexing in Solr, such as sentiment analysis (logistic regression), language detection, and topic modeling (LDA), and document classification.",https://www.youtube.com/watch?v=ASlAwlZudUk&index=8&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/solr-and-spark-for-realtime-big-data-analytics-presented-by-tim-potter-lucidworks
2015,"Austin, TX",Ted Sullivan,"Lucidworks, Inc.","Over 15 years of experience building search applications and 20+ years as a software developer. Currently focusing on Lucene/Solr as a senior solutions architect at Lucidworks.  Prior to that I did auditory neuroscience on ""fly-by-night"" critters like bats and owls that search for their prey using sound. So ""search"" seems to be a common thread to my rather eclectic career path.",Building Smarter Search Apps using built-in Knowledge Graphs and Query Introspection,Innovation,"With the recent advances in mobile technology, improving the accuracy of search results is more imperative than ever. Users want THE right answer and don't have the patience or the screen real estate to navigate long, complex result sets. This talk describes some novel techniques for using the knowledge built into the search index to dramatically improve search precision. Whether the information in a collection is structured to begin with or has been enhanced using text analytic approaches at index time, the ""knowledge graph"" that we have created for content retrieval can also be used for contextual query ""introspection"" or ""autofiltering"" - that is, using this knowledge graph to deduce the user's intent and to then return just the expected result.",https://www.youtube.com/watch?v=D76xKYgUeuQ&index=15&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/building-smarter-search-applications-using-builtin-knowledge-graphs-and-query-introspection-presented-by-ted-sullivan-lucidworks
2015,"Austin, TX",William  Moss,Airbnb,"Will Moss is a Software Engineer on the Application Infrastructure team at Airbnb. At Airbnb, Will works with the team to improve the infrastructure driving the core business. Their work currently focuses on search, but they also work on developing other services such as pricing, availability, and social connections. Before joining Airbnb Will was the first backend engineer at Bump technologies, working to build and scale their backend infrastructure before the company was acquired in 2013.",Search at Airbnb: Handling complex marketplace dynamics inside and alongside Lucene,,"Airbnb currently has over a million unique listings, which presents many challenges compared to traditional search problems. Constantly changing availability, pricing and other listing-specific features necessitate near real-time updates to ensure the best results are surfaced. Complex availability rules and request-dependant pricing computations demand novel solutions to filtering, ranking and storing the data necessary for these computations.Will Moss, software engineer at Airbnb, will discuss how Airbnb tackled these problems and built a custom search service on top of Lucene. We'll go into detail on the near real-time pipeline that keeps search up-to-date. Following that, we'll dive into the problems of availability and pricing and how to provide accurate and request-dependant information that doesn't fit well into the existing Lucene filters.",https://www.youtube.com/watch?v=cJGU6Ob2A6I&index=26&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,
2015,"Austin, TX",Joel Bernstein,Alfresco,Joel Bernstein is a Solr committer and search engineer for the open source ECM company Alfresco.,Parallel SQL,Integrations,"This presentation provides a deep dive into SolrCloud'Â»s new parallel computing capabilities. The talk will break down the framework into four main areas: shuffling, worker collections, the Streaming API and Streaming Expressions. The talk will describe how each of these technologies work individually and how they interact with each other to provide a general purpose parallel computing framework. The talk will also include a discussion of some of the core use cases for the parallel computing framework. Use cases involving real-time map reduce, parallel relational algebra and streaming analytics will be covered.",https://youtu.be/baWQfHWozXc?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/parallel-computing-with-solrcloud-presented-by-joel-bernstein-alfresco
2015,"Austin, TX",Rishi Easwaran,Aol,"I have been working with the AOL mail team since 2008 and the tech lead for our mail search infrastructure. Over the years the entire team focused on performance, availability and scalability of SOLR and in our efforts to accomplish this we dove into the source code and have a close working knowledge and experience with SOLR and SOLR Cloud.",Aol Mail Search as a service,Performance & Scale,"Our goal is to provide a high availability search as a seamless service to multiple clients. On an average our system handles more than a billion transactions per day with indexes varying in size from 1MB to 100 GB. Such size and load variation poses us a unique set of performance, availability and scalability problems to overcome, still we manage to have 10 ms update and 50 ms search times on an average.   Deployment strategy and cluster management of our tiered search infrastructure supporting over 400 TB of index its and cost savings.",https://www.youtube.com/watch?v=phpXI-Wii8w&index=39&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/mail-search-as-a-sercive-presented-by-rishi-easwaran-aol
2015,"Austin, TX",Ahmed Adel,BADR,"Ahmed is an Engineer and a Team Lead with more than 9 years of experience in developing web applications. After graduation, he worked in a multinational company for a short period then co-founded BADR in 2008 with the vision to use and innovate technology to raise the nation's renaissance. During that period, he developed and lead teams of several sizes to deliver successful solutions to several clients around the world using current technologies such as Java and JavaScript. He is also a contributor Banana, the open source fork of Kibana.",TweetMogaz: The Arabic Tweets Platform,Innovation,"TweetMogaz is a portal for browsing, filtering and searching Arabic tweets based on categories or detected news/stories. Ã±MogazÃ® (____) means in Arabic Ã±summaryÃ® or Ã±digestÃ®, which means that the platform presents a digest of (1) top/recent tweets in a specific category (2) top tweets relevant to certain topic (3) history snapshot of important tweets for a specific day. The system analyzes streams of Arabic tweets to identify trending topics, classify tweets into categories, and summarizes tweets that share the same topic. TweetMogaz is live and deployed on SolrCloud and ZooKeeper at: http://beta.tweetmogaz.com processing around 1M Arabic tweets per day. The system architecture consists of main three components: front-end, API, back-end, the archive and Banana dashboards. Each of these components is divided into several modules. For example, the back-end consists of 8 modules that pre-process, classify, index, geo-tag, take daily snapshots, detect events, and archive classified tweets. Banana dashboards provide insights and analytics about tweets stored on production and archive.",https://youtu.be/ExxiCipBrPU?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/tweetmogaz-the-arabic-tweets-platform-presented-by-ahmed-adel-badr
2015,"Austin, TX",Rama Yannam,Bank of America,"Rama is the Dev Manager at Bank of America responsible for some of the high volume applications in Online Banking along with the recently built Search engine using SOLR, Nutch, Open NLP, UIMA, Weka etc.,Viju is the lead engineer/architect on the Search solution",How to build a smart search engine with Intent detection,Integrations,"Bank of America needed to replace Microsoft FAST for website search.Å’Ã_ FAST had been in place for several years and was reaching its end of life on Linux.Å’Ã_ Since migrating to Sharepoint for the website was not an option, so bank started looking at exploring various options including an in house build using SOLR.Å’Ã_ Requirements were vastly different from a pure textual search and faceting - which SOLR is known for. We needed a system that would integrate with authenticated platforms, performs advanced spell checks, recognizes financial domain concepts, understand the user intent, and most importantly allows business and operations to tune and adjust results without technology intervention. This required us build a solution using various along with SOLR like Nutch, OpenNLP, UIMA, Weka, Tika.Å’Ã_After planning the migration for a year, the team executed the Solr development needed in about three months and deployed the new search interface to www.bankofamerica.com at the beginning of 2015.Å’Ã_",,
2015,"Austin, TX",Fred  Dushin,Basho Technologies,"Fred Dushin is a member of the technical staff at Basho Technologies, where he develops Riak KV and Yokozuna, Riak's integration with Solr Search.  Fred has worked professionally for over 15 years in the area of distributed systems and enterprise middleware, having worked as both a vendor and user of these technologies.",Distributed Search in Riak; Integrating search in a NoSQL database,,"Riak KV is an open source distributed key-value store based on the Amazon Dynamo architecture, providing high avaialbility and predicatble latency for read and write operations, while also providing deployment simplicity for operations teams.  Yokozuna is an extension of Riak KV that adds search capability to Riak, providing automatic replication and sharding of Solr indices across a Riak cluster.  This integration allows applications to quickly and effectively query data stored in Riak, while still treating it as effectively a key-value store.  This talk will outline the integration challenges faced by the Riak team, paticularly around automatic replication and sharding, and how these challenges were overcome.",https://youtu.be/e1yVJqRuLSg?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/distributed-search-in-riak-integrating-search-in-a-nosql-database-presented-by-fred-dushin-basho-technologies
2015,"Austin, TX",Chris  Mack,Basis Technology,"Chris Mack is the Director of Customer Engineering for text analytics at Basis Technology. Chris's team designs solutions and delivers services to adapt text analytic components for a broad range of customer problems. Chris has spent the last 20 years in software development, data analytics, business strategy, and business operations. Chris uses his diverse background to dive deep into data while also understanding business drivers to make new connections between customer problems and technology solutions. Chris received his BS in Management from Bentley University where he also studied Computer Information Systems.",Simple Fuzzy Name Matching in Solr,,"We all know normalization is crucial to delivering high quality search results. We don't want uninteresting variations between the query and the document to lead to missed hits (e.g., ""celebrity"" v. ""celebrities""). Normalization of dictionary words is well understood, but what if your application focuses on names? Whether you're tackling patent examination, sports records, e-commerce, watchlist screening or many other topics, names are often the key. Can your users find ""Abdul Jabbar, Karim"" if they search for ""Kareem AbdalJabar"" or ""____ ___ ______""? Solr application architects have attempted to address this through custom integration of nickname lists, edit distance, case normalization, phonetic encoding and n-grams (see example #1 or example #2), but doing so requires significant effort and may not address all desired variations. A simpler approach is to use a Solr field type for names that handles these linguistic nuances behind-the-scenes. We'll talk about how we built this sort of field type via a Solr plug-in for the Rosette Name Indexer. We'll also discuss examples of use cases this has enabled, how it can be tuned if necessary, and how it connects to the broader trend of entity-centric search. ",https://youtu.be/3UtMrQrkDlc?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/simple-fuzzy-name-matching-in-solr-presented-by-chris-mack-basis-technology
2015,"Austin, TX",Michael  Nilsson,Bloomberg LP,,Learning to Rank in Solr,,"In information retrieval systems, learning to rank is used to re-rank the top X retrieved documents using trained machine learning models. The hope is that sophisticated models can make more nuanced ranking decisions than a standard Solr query. At Bloomberg we have integrated a reranking component directly into Solr, enabling others to easily build their own learning to rank systems and access the rich matching features readily available in Solr. In this session we will review the internals of how Solr and Lucene score documents. We will then present our additions to Solr that enable feature engineering, feature extraction, and reranking. Using this new Solr component, you will be able to retrieve features for offline training and leverage the model inside Solr to rerank documents at query time.",https://youtu.be/M7BKwJoh96s?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/learning-to-rank-in-solr-presented-by-michael-nilsson-diego-ceccarelli-bloomberg-lp
2015,"Austin, TX",Ramkumar Aiyengar,Bloomberg LP,"Ramkumar leads the News Search backend team at the Bloomberg R&D office in London. He joined Bloomberg from his university in India and has been with the News R&D team for eight years now. He started working with Apache Solr/Lucene three years back, and is now a committer with the project usually curious about SolrÃ_Ã_Â»s search distribution, architecture and cloud functionality. He considers himself a Linux evangelist, and is one of those weird geeky creatures who considers Lisp beautiful and believes that Emacs is an operating system.",Building a real-time news search engine,Integrations,"What challenges could a search engine have? Large number of documents? Large query load? Very complex queries? A challenging privileging model? Expected low query latency? High volume of document updates? Updates to documents reflected in milliseconds? Realtime alerting for any search? Absolutely no downtime any time of the day, week or year? What if a search engine had all these challenges?Meet the backend which drives News Search at Bloomberg LP. In this talk, Ramkumar Aiyengar talks about how he and his colleagues successfully pushed Solr over the last three years to unchartered territories, to deliver a real-time search engine critical to the workflow of hundreds of thousands of customers worldwide.",https://www.youtube.com/watch?v=oMOV7DB4gnA&index=14&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/building-a-realtime-news-search-engine-presented-by-ramkumar-aiyengar-bloomberg-lp
2015,"Austin, TX",Nitin Sharma,BloomReach," Nitin is currently leading the Search Platform efforts at BloomReach. His background includes: Working on Large scale distributed Systems for Latency sensitive applications, Relevance and Personalization platforms, Search performance & Quality metrics infrastructure.",Automated Cluster Management & Recovery for Large Scale Multi-Tenant Search Infrastructure,Performance & Scale,"Managing cluster, index & custom SolrCloud components for a global search Infrastructure that serves millions of queries/documents is non-trivial. In a Multi-Tenant Architecture (spanning across geographies), the problem is further amplified with custom ranking components, tenant specific configuration & dynamic ranking elements that can be tweaked at collection/cluster level. At BloomReach, we have built an innovative search Architecture aimed at simple/reliable cluster, data and config management/recovery while guaranteeing 99.95% availability. The infrastructure is data center based. At the heart of the infrastructure is a Discovery Service responsible for attaching metadata to data centers based on supported tenants, roles,serving configurations,hardware spec, etc. This works in tandem with a real time Active Monitoring and Recovery Service that aid in robust failure detection and recovery.This also puts us on course to build the next generation of automation tools for deep diagnostic insights, self healing clusters & collections.The presentation will describe the infrastructure in great detail and how it achieves the availability, performance while making things simple from a platform management standpoint",https://youtu.be/IW3EglkY-R0?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/automated-cluster-management-and-recovery-for-large-scale-multitenant-search-infrastructure-presented-by-nitin-sharma-li-ding-bloomreach
2015,"Austin, TX",Patrick Beaucamp,Bpm-Conseil,"Patrick Beaucamp is founder of the Vanilla project, the only true Open Source Business Intelligence Platform, and Chairman of Bpm-Conseil, the company behind the Vanilla project. With almost 25 years of experience in the BI area, with participation in the early 90s to Business Intelligence adoption in West Europe, Patrick is leading the Vanilla project to success and recognition.Patrick was a co-writer of the best selling book ""Bpm HandBook 2010"", with a specific chapter on Open Source Bi & Bpm integration, and is a regular speaker at the Open Source Conference to talk about data visualisation.",Solr & R to deploy Custom Search Interface,Data Science,"This session will introduce the different steps needed to use R to analyze search results from Solr index, starting from the deployment of Solr & R inside an Osgi containter, through the development of custom R algorithms to analyze Solr Index resultset and user search behavior, to the different kind of interfaces available to visualize the various results (mind map or cluster of documents, user search cluster, etc ...). This session will cover topics like R, Spark, AklaBox, Visualization, Graphs",https://youtu.be/Xsef0YJmYD4?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/solr-r-to-deploy-custom-search-interface-presented-by-patrick-beaucamp-bpmconseil
2015,"Austin, TX",Mark Miller,Cloudera,"Mark Miller is a Lucene/Solr committer, PMC member, Apache member, and the current Lucene PMC chair. After starting with Lucene in 2006, Mark has spent most his time getting paid to work on the open source software projects that he loves. Mark has given many talks on Lucene/Solr at various conferences and meetups around the world and is currently learning all about Hadoop as a software engineer at Cloudera.",Developing a Big Data search engine: Where we have gone. Where we are going.,Integrations,"Lucene / Solr committer Mark Miller talks about building a search engine that can handle Hadoop scale. Spanning the beginning of  SolrCloud to the newer integrations with the Hadoop ecosystem, this talk will cover the past, present, and future of making a search engine that can run with the elephant. Want to do really big search? We are working on it. Come find out how we are doing.",https://youtu.be/Aly4vZb7XeE?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/developing-a-big-data-search-engine-where-we-have-gone-where-we-are-going-presented-by-mark-miller-cloudera
2015,"Austin, TX",Yonik Seeley,Cloudera,"Yonik Seeley is the creator of Solr. He is an expert in distributed search systems architecture and performance. Yonik has been a prolific Lucene/Solr committer, a member of the Lucene/Solr PMC, and a member of the Apache Software Foundation. Yonik works at Cloudera integrating and leveraging Big Search & Analytics technologies into the many components comprising the Cloudera enterprise data hub (EDH).  Prior to Cloudera his work experience includes Heliosearch (founder), LucidWorks (co-founder), CNET Networks, BEA and Telcordia. He earned his M.S. in Computer Science from Stanford University.",Real-time Analytics with Solr,,"Search engines have come a long way, from relative obscurity as niche products only used to address full-text search problems, to general purpose full fledged members of the NoSQL gang that developers turn to first to help solve a great variety of problems.This talk will cover how search and Solr have become a critical part of the Hadoop stack, and have also emerged as one of the highest performing solutions for analytics over big data.We'll also cover new analytics capabilities in Apache Solr that marry full-text search, faceted search, statistics, grouping, and joins into a powerful engine for powering next generation big data analytics applications.",https://www.youtube.com/watch?v=JtbEDef_p9U&index=40&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/realtime-analytics-with-solr-presented-by-yonik-seeley-cloudera
2015,"Austin, TX",David Smiley,D W Smiley LLC,"David Smiley is a well recognized Apache Lucene/Solr expert.  He wrote the first book on Solr, he's a Lucene/Solr committer and PMC member that improves Lucene and Solr, he speaks at conferences about it, he does training, and he offers part time independent consulting services / development.  Much of Lucene's spatial module was developed by David.",Lucene/Solr Spatial in 2015,Innovation,"2015 is a big year for spatial in Lucene/Solr! This presentation will review the new features thru October. The features to be covered will at least include the following: Heatmaps: Solr can generate gridded facet counts, and fast. See a live demo; PackedQuadPrefixTree: A more compact and efficient alternative to QuadPrefixTree; FlexPrefixTree: A configurable spatial tree to balance index size with search speed; RptWithGeometrySpatialField: An RPT index paired with serialized geometry with an in-memory cache allows indexed shapes to be searched accurately and quickly; Geo3D: Polygons and other shapes computed on the surface of a sphere or ellipsoid. It's also very fast when point data is pre-converted to 3 dimensions;  GeoPointField: A leaner alternative to RPT; BKDTree / BKDPointField: An experimental Lucene codec for spatial data. It's very efficient; RPT spatial indexes for non-point data are 40% leaner; find out how/why; Solr spatial ease-of-use improvements, to include distance units, a nicer Solr query parser, and GeoJSON format.",https://youtu.be/9zeYRisbx5E?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/lucenesolr-spatial-in-2015-presented-by-david-smiley
2015,"Austin, TX",Simon Hughes,Dice.com,"I am the Chief Data Scientist at Dice.com, where I've built a number of successful recommender engines and performed search relevancy tuning on our solr platform, as well as implemented many solr plugins for custom functionality. I am also a PhD Candidate at DePaul, studying Machine Learning and Natural Language processing.",Implementing Conceptual Search in Solr using LSA and Word2Vec,Innovation,"We will discuss various strategies for implementing concept search in a scalable manner directly in a solr server. Concept search moves beyond pure keyword matching to matching documents based on conceptual similarity to a query. By clustering terms and also by learning vector representations for words and documents, we can implement concept search in solr in a fast, accurate and scaleable manner. Traditional Boolean  search engines return a lot of results that include too many irrelevant items and miss a lot of relevant items due to the problems of synonymy and polysemy. By computing semantic vectors for documents, we overcome these problems by projecting the documents into a vector space where the core concepts of the documents themselves are represented. By then using the solr re-ranking functionality, we can implement concept search by re-ranking the top search results based on conceptual similarity to the original query without sacrificing performance. We will also discuss how we have experimented with using clustering approaches to learn topics over words in our domain, such as ""Big Data"" and ""Front End Technologies"" and configured those topics in a separate field using synonyms and payloads.",https://www.youtube.com/watch?v=WYOkb1BQG2E&index=49&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/implementing-conceptual-search-in-solr-using-lsa-and-word2vec-presented-by-simon-hughes-dicecom
2015,"Austin, TX",Fiona Condon,Etsy,"Fiona Condon is a software engineer on Etsy's search experience team. She works to make Etsy's vast marketplace easy and fun to explore, with a focus on internationalization. She lives in Brooklyn and likes to play music and video games.",Nice Docs Finish First: Designing Search Ranking for Fairness at Etsy,Innovation,"Many search systems are designed to retrieve and rank documents authored by real people who want to be found and will modify the information they give to achieve a top spot. Conscious ranking decisions can make the system fairer and more relevant for searcher and searchee alike. Search at Etsy is engineered to reward sellers who provide honest and straightforward information and to help buyers find a diverse selection of relevant, high-quality items with minimal friction. I'll discuss best practices for developing, maintaining and evaluating a robust and fair ranking system in the context of a competitive environment.",https://youtu.be/W4AWXx8IgoI?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/nice-docs-finish-first-designing-search-ranking-for-fairness-at-etsy-presented-by-fiona-condon-etsy
2015,"Austin, TX",Gregg Donovan,Etsy.com,"Gregg Donovan is a Senior Software Engineer at Etsy.com in Brooklyn, NY, working on the Solr and Lucene infrastructure that powers more than 120 million queries per day. Gregg spoke at Lucene Revolution 2011 in San Francisco, Lucene Revolution 2013 in San Diego, and previously worked with Solr and Lucene at TheLadders.com.",Lessons from Sharding Solr at Etsy,Innovation,"We will discuss lessons learned at Etsy while sharding Solr. Among them: How to enable SolrJ to handle distributed search fanout and merge, saving a network hop and easing performance analysis and GC tuning of both fanout/merge and the shards; How to instrument Solr for distributed tracing (a la Google's Dapper, Twitter's Zipkin, or Etsy's CrossStitch) so that distributed searches may be better understood, analyzed, and debugged; We will dive into strategies for managing latency in distributed search, including tolerating partial results and issuing backup requests in the presence of lagging shards. We hope to open source the work we've done on both before the talk.",https://youtu.be/_IWkrBmzQ2g?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/lessons-from-sharding-solr-at-etsy-presented-by-gregg-donovan-etsy
2015,"Austin, TX",Matt  Pearce,Flax,"Co-founder of Flax, leading specialists in open source search, Charlie Hull regularly blogs, tweets and talks about search. Charlie also runs the London Lucene/Solr User Group.",Searching the Stuff of Life: BioSolr,Innovation,"Over the last year Flax has been working with the European Bioinformatics Institute (EBI) on a publically funded project, BioSolr: ""to significantly advance the state of the art with regard to indexing and querying biomedical data with freely available open source software"". Working directly with bioinformaticians, Flax has created new features and capabilities, some of which have already become part of recent releases of Solr. These features include improvements to faceting, a way to use external similarity systems for JOINs, querying & boosting, and methods to index and search ontologies. These features are already part of search applications including the Protein Databank in Europe (PDBe), used by thousands of scientists. Future plans include using the distributed querying capabilities of Solr to create a federated search across many co-operating institutions. Charlie will also explain how the  funding has made it possible to enhance Solr not just for bioinformaticians but for the wider community.",https://youtu.be/v1qKNX_axdI?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/searching-the-stuff-of-life-biosolr-presented-by-matt-pearce-alan-woodward-flax
2015,"Austin, TX",Aurelien Mazoyer,France Labs,"Aurelien is an expert in search, specialised on Apache Solr, Apache ManifoldCF, Datafari and security. For a living, Aurelien gives trainings on Solr, provides technical audits and consulting around Solr to demanding customers. He has a ""French IT Engineer"" degree from Polytech'Nice.",Properly integrate ManifoldCF with Apache Solr,Integrations,"Documents ingestion is a crucial step for search, but only a handful of available open source connectors framework are available. Among them, ManifoldCF is the most advanced. Its integration with Apache Solr is not an obvious thing, as shown by the popularity of our technical blog on this aspect. Since we've been integrating ManifoldCF and Solr for a few years now, we want the audience to benefit from our experience in order quickly ramp up on that in their own projects.",https://youtu.be/_TlYn_E5loM?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,?
2015,"Austin, TX",Devansh Dhutia,Gannett Co. Inc.,"Devansh joined the Gannett family in 2006 and has been an active contributor to Gannett's search strategy starting with Lucene, and for the last 2 years, Solr. Devansh was one of the primary developers involved in switching Gannett from the traditional master-slave solr setup to a geo-replicated Solr Cloud environment. When Devansh isn't working with Solr, he enjoys spending time with his wife & 3 year old daughter and trying new recipes.",Queue based Solr Indexing with collection management,Performance & Scale,"Deploying schema-changes to solr collections with large volumes of data can be problematic when the reindex activity can take almost a whole day. Keeping in mind that Gannett's 16 million document index grows by approximately 800,000 documents per month, the status quo isn't satisfactory. A side effect of the current architecture is that during a Solr outage, not only are all reindex activities paused, but upstream authoring engines suffer from latency issues.This talk will demonstrate how Gannett is switching to a queue based solution with creative use of collections & aliases to dramatically improve the deployment, reindex, and authoring experiences. The solution also incorporates keeping a pair of Solr clouds in geographically dispersed data centers in an eventually synchronized state.",https://youtu.be/bNWuyH8p0fg?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/queue-based-solr-indexing-with-collection-management-presented-by-devansh-dhutia-gannett-co
2015,"Austin, TX",Mikhail Khludnev,"Grid Dynamics, Inc.","Mikhail has years of experience building backend systems for retail industry. His interests span from general systems architecture, API design and performance engineering all the way to testing approaches. For last few years he works on eCommerce search platform extending Lucene and Solr, contributes back to community, spokes at Lucene Revolution and other conferences.",Scorer's Diversity. Phase 2.0,,"Lucene has number of built-in queries, but sometimes developers need to write their own queries that might be challenging. We'll start from the basics: learn how Lucene searches, look into few built-in query implementations, and learn two basic approaches for query evaluation. Then I'll share my team's experience in building one eCommerce Search platform, we'll look at sample custom queries, and talk about potential problems and caveats. We'll also observe recent changes such as two phase iterators, in-order only scoring, etc.",https://youtu.be/BM4-Mv0kWr8?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/scorers-diversity-phase-20-presented-by-mikhail-khludnev-grid-dynamics-inc
2015,"Austin, TX",Anshum Gupta,IBM Watson,"I am a committer and PMC member on the Apache Lucene / Solr project with about 10 years of experience with search and related technologies. I currently work at Lucidworks and spend most of my time working on SolrCloud i.e. the distributed feature set of Apache Solr. Prior to joining Lucidworks, I was a member of the team that developed and launched AWS CloudSearch - The AWS search as a service offering. I was also a key contributor in the search teams at various startups.",Understanding the Solr Security Framework,Integrations,"Apache Solr has evolved into a highly scalable system, capable of handling a lot of data and high number of queries but only recently was a mechanism to secure access in Solr provided. Apache Solr 5.2 shipped with pluggable authentication and authorization modules. These modules enable users to write their own plugins for managing security in Solr.This talk would cover an overview of both the frameworks, and how they work together within Solr. It will provide a brief overview of existing plugins and also cover writing a custom authorization plugin that allows for restricting users based on simple rules. At the end of this talk, intermediate Solr users will have a better understanding of how the security framework works and how it could be used with custom plugins. Attendees would also know more about existing security plugins for both the frameworks e.g. Kerberos plugin for authentication.",,http://www.slideshare.net/lucidworks/understanding-the-solr-security-framekwork-presented-by-anshum-gupta-ibm
2015,"Austin, TX",Peter Gazaryan,Macy's Inc.,I started my career in IT working on natural language processing applications at a university lab in New Mexico. During the first dot com boom of the early 2000s I shifted my focus to eCommerce. I joined macys.com in San Francisco at the time of the company's first Java-based web site launch. Thereafter I have been actively contributing in multiple areas of macys.com development as an engineer and a solution architect. Since early 2011 I have been leading a team responsible for customer-facing keyword search and guided catalog navigation services. Our Solr-based platform debuted in the Summer of 2013.,Deep Data at Macys: Searching Hierarchical Documents for eCommerce Merchandising,Innovation,"Traditional notion of relevance focuses on the ""information need"". In eCommerce, online customer's ""information need"" is the desire to locate and obtain information about products. A naÂ¥ve approach to product catalog search focuses entirely on the customer's query (submitted both explicitly and implicitly), and ranks the results using standard methods, such as TF/IDF. While this methodology may be good for general purpose eCommerce venues like online bazaars, it ignores the key tenet of the Department Store business model: Merchandising. The practice of Merchandising introduces a data curator's point of view. This new point of view expands the notion of information need, and imposes a tradeoff between natural and curated result. Moreover, it redefines the search result itself, demanding performant cross-entity false positive match elimination and dynamic grouping and ungrouping with respect to the relational eCommerce catalog structure. At Macy's we have expanded Solr with advanced Merchandising capabilities: fine-grained control of precision over recall, dynamic grouping and ungrouping of related entities, cross-entity match elimination, rule-driven search query rewriting, and combinatorial concept search. We will describe the history of Macy's implementation and highlight some lessons learned.",https://youtu.be/mKxQBechNiE?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/deep-data-at-macys-searching-hierarchichal-documents-for-ecommerce-merchandising-presnted-by-peter-gazaryan-macyscom-eugene-steinberg-grid-dynamics-inc
2015,"Austin, TX",Gabriel Arnett,Moodys Analytics,Technologist with 25+ years of disrupting the enterprises with the right tools for the right jobs. Taking down one monolith at a time is my mission and I will not stop till I've succeeded in putting things right that the so called enterprise ready solutionists have destroyed in their paths. Presently focused on harnessing a minor hill of information and deriving new values by enabling self discovery to find what lies in the mire.,From What? To Discovery Enablement,Innovation,"What if you could give a business user, a user experience engineer, an ontologist librarian, search strategists and front end engineers in the driver seat and allow them to define, test and implement search functionalities across application end points in a 1/8th of the time with 1/16th of the resources? What if there was a search solution that would cost a mere fraction and allow you to remove the 7 figure noose from around your IT budget neck and allow you to do more with less? Using Lucidworks Fusion with Solr, we have done just that and then some enabling us to take the next leaps in the direction to build an interactive experience for our user base to keep them coming back to look for more.",https://youtu.be/wKsJ5ALzCeE?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/from-what-to-discovery-enablement-presented-by-gabe-arnett-moodys-analytics
2015,"Austin, TX",Upayavira ,Odoko Ltd,"Upayavira has been working with Apache Solr since 2008, and teaching training courses about it since 2010. He is a member of the Apache Software Foundation. Recently, he has been contributing an update to the Solr Admin UI that makes use of AngularJS - aiming to facilitate greater innovation and faster feature development.",Understand the breadth and depth of Solr via the Admin UI,,"The Solr AdminUI is a surprisingly comprehensive tool that can be very effective in exploring what is going on within a Solr installation. In this presentation, we will use the admin UI to index data, query that data, introspect what how that data is analysed into the index, review analysis pipelines, and much more. Using the UI will allow us to dive deeper under the bonnet and see exactly how Solr is behaving and why, and can really help when debugging a Solr installation that isn't behaving as we expect.",https://www.youtube.com/watch?v=05Oh_Quukr4&index=37&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/understand-the-breadth-and-depth-of-solr-via-the-admin-ui-presented-by-upayavira
2015,"Austin, TX",Taka Shinagawa,,,"""Spark Search"" In-memory, distributed search with Lucene, Spark and Tachyon",Integrations,"This talk will present the motivation, implementation, performance evaluation and use cases of a new in-memory distributed search system with Lucene, Spark and Tachyon. The presentation will include how to index and query data in Spark's batch mode, Streaming and SQL, usage in the machine learning pipelines, and a new Lucene Directory implementation for Tachyon, a memory-centric distributed filesystem.",,
2015,"Austin, TX",George Bailey,Rackspace,Software Developer for Rackspace Email Infrastructure,Rackspace Email's solution for indexing 50k documents per second,Performance & Scale,"Customers of Rackspace Email have always needed the ability to search and review login, routing, and delivery information for their emails.  In 2008 a solution was created using Hadoop MapReduce to process all of the logs from hundreds of servers and create Solr 1.4 indexes that would provide the search functionality.  Over the next several years, the number of servers generating the log data grew from hundreds to several thousands which required the cluster of Hadoop and Solr 1.4 servers to grow to ~100 servers.  This growth caused the MapReduce jobs for indexing the data to take anywhere from 20 minutes to several hours.In 2015 Rackspace Email set out to solve this ever growing need to index and search billions of events from thousands of servers and decided to leverage SolrCloud 5.1.  This sessions will discuss how over ~100 physical servers were replaced with 10 physical servers running SolrCloud 5.1.  Additionally, the functionality provided with SolrCloud allows for this stream of documents to be indexed and searchable within 5 seconds.  This was a big win for Rackspace Email and all of their customers that rely on their service each day.",https://youtu.be/-u_GUc5M1L8?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/rackspace-emails-solution-for-indexing-50k-documents-per-second-presented-by-george-bailey-cameron-baker-rackspace
2015,"Austin, TX",Chris Bredesen,Red Hat,"As a part of the Customer Experience and Engagement team, Chris manages the global engineering organization responsible for the Red Hat Customer Portal and related services.",Evolving to Open: Adopting Apache Solr for the Red Hat Customer Portal,,"Join the Red Hat engineering team for an overview of their journey from a proprietary search appliance to an open source Solr infrastructure. You'll learn what motivated the change and experience some of the challenges encountered in migrating 500,000 documents and adding on another 10 million along the way. Dive into the mechanics of indexing content from disparate sources including Drupal, Salesforce and various custom web applications. See the key performance indicators (KPIs) used to gauge initial success and ongoing search quality.",https://youtu.be/u4TXFjMVFQ0?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/evolving-to-open-adopting-apache-solr-for-the-red-hat-customer-portal-presented-by-chris-bredesen-red-hat
2015,"Austin, TX",Brett Hoerner,Rocana,"Brett Hoerner lives in Austin, TX and is an Infrastructure Engineer at Rocana where they are helping clients control their global-scale modern infrastructure using big data and machine learning techniques. He began using SolrCloud in 2012 to index the Twitter firehose at Spredfast, where the collection eventually grew to contain over 150 billion documents. He is primarily interested in the performance and operation of distributed systems at scale.",Solr at Scale for Time-Oriented Data,Performance & Scale,"This talk will go over tricks used to index, prune, and search over large (>10 billion docs) collections of time-oriented data, and how to migrate collections when inevitable changes are required.",https://youtu.be/u5_vzcYYWfc?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/solr-at-scale-for-timeoriented-data-presented-by-brett-hoerner-rocana
2015,"Austin, TX",Tomoko Uchida,"RONDHUIT Co.,Ltd.","Graduated from Chiba University, the Department of Electrical and Electronics Engineering, the Faculty of Engineering. Worked for several software companies before founding RONDHUIT, the Apache Lucene/Solrconsulting/training service provider. Building own career in search engine industry, natural language processing was added to the target of interest. Enrolled in Japan Advanced Institute of Science and Technology in 2012 to major in natural language processing and received a master's degree in information science in 2014.Apache Lucene/Solr Committer and a member of PMC.",An Introduction to NLP4L: Natural Language Processing Tool for Apache Lucene,,"NLP4L is a natural language processing tool for Apache Lucene written in Scala.The main objective of this OSS project is to use NLP technologies to improve Lucene users' search experience. The unique difference between NLP4L and other NLP tools is that NLP4L itself references Lucene index instead of raw text as its processing target. The session will describe how to use Scala to obtain word statistics and N-gram statistics from Lucene index and introduces various tools including the Hidden Markov model that are developed using these functions.",https://www.youtube.com/watch?v=v_22bdxdDc0&index=25&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/an-introduction-to-nlp4l-natural-language-processing-tool-for-apache-lucene-presented-by-tomoko-uchida-rondhuit-co-ltd
2015,"Austin, TX",Paul  Nelson,Search Technologies,"Paul was an early pioneer in the field of text retrieval and has worked on search engines for over 25 years. He was the architect and inventor of RetrievalWare, a ground-breaking natural-language based statistical text search engine which he started in 1989 and grew to $50 million in annual sales worldwide. RetrievalWare is now owned by Microsoft Corporation. Paul has been involved in hundreds of text search installations includes enterprise search for dozens of fortune 500 corporations as well as large government organizations. At Search Technologies, Paul provides architectural oversight for clients' projects and conducts design, technology research and training.  ",Search Accuracy Metrics & Predictive Analytics _ A Big Data Use Case,Data Science,"With Big Data, it is now possible to harvest user event data, such as search logs and click logs, for the purpose of computing user-based search accuracy metrics. These metrics can determine how well your search engine is satisfying the needs of your user population.Siting examples from recent eCommerce and Recruiting industry engagements using Solr, this presentation will describe algorithms and processes for computing search accuracy metrics. These metrics are enormously helpful for computing and comparing search engines for accuracy before the engine is deployed. We will then extend these methods to include predictions of business metrics (conversion rate and abandonment rate), machine learning for relevancy optimization, and how optimized relevancy formulae can be incorporated into Lucene-based search engines using custom Lucene relevancy operators.",https://youtu.be/m7yRn3UqNbg?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/search-accuracy-metrics-and-predictive-analytics-a-big-data-use-case-presented-paul-nelson-search-technologies
2015,"Austin, TX",Rafal Kuc,"Sematext Group, Inc.","Rafa_ â€° - father, husband, Sematext software engineer and consultant, Solr Cookbook and Elasticsearch Server books author, http://solr.pl co-founder.Radu - Search and logging geek at Sematext, working daily with the likes of Elasticsearch, Logstash and rsyslog. Co-authoring Elasticsearch in Action",Large Scale Log Analytics with Solr,Data Science,"This talk is about searching and analyzing time-based data at scale. Documents ranging from blog posts and social media to application logs and metrics generated by smart-watches and other smart-things share a similar pattern: timestamp among their fields, rarely changeable, deletion when they become obsolete. Because very often this kind of data is so large that it causes scaling and performance challenges. In this talk we'll address precisely these challenges, which include: properly designing collections architecture, indexing data fast and without documents waiting in queues for processing, being able to run queries that include time based sorting and faceting on enormous amounts of indexed data without killing Solr with out of memory problems, and many more.We'll start with the indexing pipeline - where you do all your ETL. We'll show you how to maximize throughput through various ETL tools, such Flume, Kafka, Logstash and rsyslog, and make them scale and send data to Solr. On the Solr side, we'll show all sorts of tricks to optimize indexing and searching: from tuning merge policies to slicing collections based on timestamp. While scaling out, weÃ_Ã_Â»ll show how to improve the performance/cost ratio.",https://www.youtube.com/watch?v=TPJ5e0ibc9s&index=12&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/large-scale-log-analytics-with-solr-presented-by-rafa-ku-radu-gheorghe-sematext-group-inc
2015,"Austin, TX",Toke Eskildsen,"State and University Library, Denmark","Toke Eskildsen has worked on all things search for 7 years at the State and University Library, Denmark. As part of his work he maintained the in-house search engine Summa, build on Lucene. During that time he developed a faceting module, capable of hierarchical faceting as well as scaling to thousands of fields. In the last couple of years, his focus has been on Solr and scaling up.",Faceting optimizations for Solr,,"Using Solr for interactive search of the material in the Danish Net Archive (500TB+ raw data, which is reduced to 1/10th when indexed) proved to be surprisingly painless in most aspects. However, faceting speed for billions of values on a single machine was not satisfactory.Spawned by this, the Open Source Sparse Faceting project at http://tokee.github.io/lucene-solr/ contains multiple improvements to vanilla Solr for high-cardinality String faceting. This talk will present the most interesting ones:- Counter re-use for lower response time and less garbage collection.- Counter tracking for linear scaling of response extraction time to result size instead of corpus size.- Packed counters for lower memory requirements.- Multi threaded counting for machines with CPU-power surplus.- Changes to SolrCloud distributed faceting for lower response time.This talk is based on ""Solr sparse faceting"" presented at Berlin Buzzwords 2015. It does not require in-depth knowledge of Solr faceting but does contain non-trivial diagrams of bit packing structures and the occasional big O notation.",https://www.youtube.com/watch?v=klwliAOiINY&index=50&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/faceting-optimizations-for-solr-presented-by-toke-eskildsen
2015,"Austin, TX",Lianyi Han,The National Center for Biotechnology Information,"Senior bioinformatics scientist with over 18 years of experience, 50+ peer-reviewed scientific journals in Bioinformatics and Computational Biology.  IT specialist with 17+ years of experience in UI/UX development, DBA/DBO  in RDBMS and NoSQL, proven ability to offer solutions in software architect, development, stress/unit/split testing, deployment and optimization.",Seqr:  protein sequence search,Innovation,"One of the most challenging task in biomedical search domain, is to effectively indexing the flood volume of sequences resulting from the next-gene sequencing technologies. Solr has been a great text search engine, but how about searching protein sequences, perhaps even chemicals and other complex objects in solr?  In this talk, we'd like present our most recent work on adding tanimoto score implementation and how we search protein sequences, and small molecular structures in Solr.",https://youtu.be/CUebVbibxfM?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/seqr-protein-sequence-search-presented-by-lianyi-han-medical-science-computing-lewis-geer-nih
2015,"Austin, TX",Alexandre Rafalovitch,United Nations,"Alexandre is a full-stack IT specialist with close to 20 years ofindustry and non-profit experience, including in Java, C# andHTML/CSS/JavaScript. He develops projects on Windows, Mac and Linux.His current focus is on popularizing Apache Solr. Alex has written onebook about Solr already (Apache Solr for Indexing Data How-to). He haspresented at Lucene/Solr Revolution 2014, as well as multiple times atJavaOne and various smaller venues.",Solr troubleshooting - TreeMap approach,Innovation,"Solr is too big of a product to troubleshoot as if it were a black box or by random tests. Fortunately, there is a way to use Solr's API, logs, specific queries, and even source code to iteratively narrow a problem definition to something concrete and fixable. Solr already has most of the tools for good troubleshooting, but they are not positioned or documented as such. Additionally, there are various operating system tools that can be used for troubleshooting Solr. This talk will give the attendees the mental model and practical tools to become better troubleshooters with their own Solr projects.",https://youtu.be/rS0yeD46N1Q?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/solr-troubleshooting-treemap-approach-presented-by-alexandre-rafolovitch-united-nations
2015,"Austin, TX",Joaquin Delgado,Verizon,"Joaquin A. Delgado, PhD. is currently Director of Advertising and Recommendations at OnCue (acquired by Verizon).  Previous to that he held CTO positions at AdBrite, Lending Club and TripleHop Technologies (acquired by Oracle). He was also Director of Engineering and Sr. Architect Principal at Yahoo! His expertise lies on distributed systems, advertising technology,  machine learning, recommender systems and search. He holds a Ph.D in computer science and artificial intelligence from Nagoya Institute of Technology, Japan.",Where Search meets Machine Learning,,"Search engines have focused on solving the document retrieval problem, so their scoring functions do not handle naturally non-traditional IR data types, such as numerical or categorical. Therefore, on domains beyond traditional search, scores representing strengths of associations or matches may vary widely As such, the original model doesn't suffice, so relevance ranking is performed as a two-phase approach with 1) regular search 2) external model to re-rank the filtered items. Metrics such as click-through and conversion rates are associated with the users' response to responses served. The predicted selection rates that arise in real-time can be critical for optimal matching. For example, in recommender systems, predicted performance of a recommended item in a given context, also called response prediction, is often used in determining a set of recommendations to serve in relation to a given serving opportunity. To address this issue the authors have created ML-Scoring, an open source framework that tightly integrates machine learning models into a popular search engine (SOLR/Elasticsearch), replacing the default IR-based ranking function. A custom model is trained through either Weka or Spark and it is loaded as a plugin used at query time to compute custom scores.",https://youtu.be/i4Y1DaPmBT4?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/where-search-meets-machine-learning-presented-by-diana-hu-joaquin-delgado-verizon
2015,"Austin, TX",Shenghua Wan,WalmartLabs,Shenghua Wan is a Senior Software Engineer and Varun Srivastava is a Principal Software Engineer in Polaris Search Team in WalmartLabs. Their focus is applying big data technologies to deal with large-scale product information to be searched online.,Solr distributed indexing in WalmartLabs,Integrations,"As a retail giant, Walmart provides millions of items information via its e-commerce websites, and the number grows quickly. This calls for big data technologies to index the documents. Map-Reduce framework is a scalable and high-available base on top of which the distributed indexing can be built. While original Solr has a map-reduce index tool, there exist some barriers, which makes it unable to deal with our use cases very easily and efficiently. The barriers include documentation, Hadoop API versions, MapR file system, XML input format, removing the need for ZooKeeper and etc. More importantly, the original MapReduceIndexTool is inefficient for our use case. In this case study, we will demonstrate a way to build your own distributed indexing tool from it, and optimize the performance by making the indexing stage a map-only job before they are merged.",https://www.youtube.com/watch?v=Qc96NNc__vY&index=24&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/solr-distributed-indexing-in-walmartlabs-presented-by-shengua-wan-walmartlabs
2015,"Austin, TX",Tom Burgmans,Wolters Kluwer,"Tom Burgmans currently works as a Search Specialist for Wolters Kluwer, a publisher for professional content. He is responsible for maintaining and improving the quality of the search experience in the online information delivery platforms.Tom has over 9 years of experience in search, deployed various enterprise search systems during his employment at Autonomy, improved relevancy of the discovery platforms at Wolters Kluwer where he also guided the transition from commercial to open source search technologies.",When you have to be relevant,,"When the search engine is a value driving component of your digital platform, its results has to be spot-on with respect to relevancy. But relevancy is hard to measure and if something is hard to measure it's hard to improve. Solr has many ways to influence and modify the scoring algorithm. It's feedback is also fully transparent. Yet with the amount of options and loads of EXPLAIN information to analyze, one could easily lose focus. Especially when the spot on the horizon isn't always clear.In this session we'll zoom in on a methodology that is developed and matured over the past 4 years at Wolters Kluwer, which transforms the abstract notion of relevancy into concrete numbers and which systematically drives the quality of relevance to higher levels. We will demonstrate a structured way of working to boost relevancy, as well as an in-house developed tool set that visualizes relevancy at macro- and micro level. This methodology was and still is key for driving the value of Wolters Kluwer's online products. When you have to be relevant, this session is for you.",https://www.youtube.com/watch?v=4tcizH8b5pY&index=36&list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,
2015,"Austin, TX",Erick Erickson,"Workplace Partners, LLC.","Erick is a Lucene/Solr committer and regular contributor to the Apache mailing list. Erick got his start with Lucene in 2006 and since has helped  companies use Solr and Lucene in a variety environments. In his spare time, Erick is an avid outdoorsman Ã_Ã_Ã® often hiking, canoeing, and sailing. Special deals available for owners of sailboats in the San Francisco area who need occasional crew. He received his MS from the University of Michigan, Ann Arbor, MI. more years ago than he wants to remember.",Streaming Aggregation in Solr: New horizons for Search,,"Streaming Aggregation (SA) brings new capabilities to the Solr/Lucene ecosystem. SA can leverage the distributed nature of SolrCloud to allow ad-hoc queries over very large result sets. The results of these queries can then be assembled by lightweight SolrJ clients to perform analytics and cross-collection joins to mention just two.SA can be applied to any DocValues fields, and can achieve very high throughput; on the order of 400,000 records/second exported per node. The additional capability of distributing processing those streams to arbitrary sets of Solr nodes then only returning the results of that processing to the client allows massive scaling.Streaming Aggregation, like all implementations, is well suited to certain types of problems. There are other classes of problems that are a poorer fit. This talk will focus on introducing the audience to the concepts behind SA,  some of the problems that do and do not fit into the SA model, and show how simple it is to program a client to use SA.",https://youtu.be/n5SYlw0vSFw?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/streaming-aggregation-in-solr-new-horizons-for-search-presented-by-erick-erickson
2015,"Austin, TX",Dragan Milosevic,Zanox AG,"Dr. Dragan Milosevic is a certified Solr/Lucene, Hadoop and HBase developer and currently works as Chief Search Architect at zanox in a Distributed Computing Team that successfully uses several Apache open-source projects for building a world-class reporting framework. He is also author of a book Ã±Beyond Centralized  Search Engines: An Agent-Based Filtering FrameworkÃ® that describes the application of various machine-learning techniques for solving cooperation and coordination challenges in distributed systems. His several  talks on recognized conferences about built reporting framework already uncovered details regarding version-mismatch handling during communication, aggregation map-reduce jobs, resource-aware query routing and search analytics for guiding index-building.",OLAP Battle: SolrCloud vs. HBase,Data Science,"Real time data mining powered by Online Analytical Processing (OLAP) has become essential for a broad range of users who aim to rapidly gain insights and benefit from collected data. To adequately support those users, the open-source community has nurtured several scalable systems that can efficiently execute OLAP queries even on collections of nearly unlimited size. SolrCloud and HBase are two such systems, whose scalable solutions for supporting OLAP queries will be profoundly analyzed and systematically evaluated in different scenarios to support architects chose the right technology. On the one hand, SolrCloud can easily support OLAP queries thanks to its column-based storage of fields with Lucene doc-values that are extremely memory friendly. Doc-values are also very flexible as every field is separately indexed and completely independently accessed while searching. On the other hand, HBase provides end-point coprocessors that are used to inject any custom functionality, such as computing aggregations, directly into region servers where fields are indexed inside column families and accessed together while searching. Consequently, the structure of column families should be optimized for OLAP queries in order to maximize the benefits of an internal block-cache and increase the efficiency of a single index that is shared among all fields.",https://youtu.be/F7DIGgliu0Q?list=PLU6n9Voqu_1E39VLCYTgPj5Wk9GhZpoTb,http://www.slideshare.net/lucidworks/olap-battle-solrcloud-vs-hbase
2014,"Washington, DC",Trey Grainger,CareerBuilder,,Semantic & Multilingual Strategies in Lucene/Solr,Tutorial,"When searching on text, choosing the right CharFilters, Tokenizer, stemmers and other TokenFilters for each supported language is critical. Additional tools of the trade include language detection through UpdateRequestProcessors, parts of speech analysis, entity extraction, stopword and synonym lists, relevancy differentiation for exact vs. stemmed vs. conceptual matches, and identification of statistically interesting phrases per language. For multilingual search, you also need to choose between several strategies such as 1) searching across multiple fields, 2) using a separate collection per language combination, or 3) combining multiple languages in a single field (custom code is required for this and will be open sourced), all with their own strengths and weaknesses depending upon your use case. This talk will provide a tutorial (with code examples) on how to pull off each of these strategies. We will also compare and contrast the different kinds of stemmers, discuss the precision/recall impact of stemming vs. lemmatization, and describe some techniques for extracting meaningful relationships between terms to power a semantic search experience per-language. Come learn how to build an excellent semantic and multilingual search system using the best tools and techniques Lucene/Solr has to offer!",https://www.youtube.com/watch?v=MQ6WtBw8T_U&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=41,http://www.slideshare.net/lucidworks/semantic-multilingual-strategies-in-lucenesolr-presented-by-trey-grainger
2014,"Washington, DC",Andrew Thanalertvisuti,Lucidworks,,Visualize Solr Data with Banana,Internals,"The talk will be both tutorial and description of an implementation of the open source Banana project, which is a port of Kibana project for Solr. I will talk about how the project got started, what we did to port Kibana to Solr and show the audiences where they can download and setup Banana to talk with their Solr instances. I will also show how developers can extend Banana's capabilities by developing their own custom modules for the dashboard panels.",https://www.youtube.com/watch?v=cqV5lPM2VVE&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=29,http://www.slideshare.net/lucidworks/visualize-solr-data-with-banana-presented-by-andrew-thanalertvisuti
2014,"Washington, DC",Grant Ingersoll,Lucidworks,,This Ain't Your Parent's Search Engine,Open Source / Industry,"In just a few short years, search has quickly evolved from being a small text box in the nether regions of a website to being front and center in our lives. Increasingly, however, the combination of search engine and Hadoop technology is also being used for practical, real time recommendations, events processing, complex spatial functionality, and time series analysis capable of not only matching user's queries in text, but also driving real time decision making and analytics.  In fact, open source Apache Lucene/Solr can do all of this and more by taking advantage of new data structures and algorithms as well as deeper integration with Hadoop and related projects.  In this demo-driven talk, we will take a look at some of the new and exciting ways users are leveraging Lucene/Solr and big data to drive deeper insight into information needs that go beyond keywords in a text box.",,
2014,"Washington, DC",Shalin Shekhar Mangar,Lucidworks,,Scaling SolrCloud to a Large Number of Collections,Internals,"The traditional and typical search use case is the one large search collection distributed among many nodes and shared by all users. However, there is a class of applications which need a large number of small or medium collections which can be used, managed and scaled separately. This talk will cover our effort in helping a client set up a large scale SolrCloud setup with thousands of collections running on hundreds of nodes. I will describe the bottlenecks that we found in SolrCloud when running a large number of collections. I will also take you through the multiple features and optimisations that we contributed to Apache Solr to reduce or remove the choke points in the system. Finally, I will talk about the benchmarking process and the lessons learned from supporting such an installation in production.",https://www.youtube.com/watch?v=nxRROble76A&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=37,http://www.slideshare.net/lucidworks/scaling-solrcloud-to-a-large-number-of-collections-shalin-shekhar-mangar
2014,"Washington, DC",Tomas Fernandez Lobbe,A9,,"CloudSearch, the Amazon Web Service on top of Solr",Use Case,Amazon CloudSearch is the fully-managed search service in the AWS Cloud and it is now powered by Apache Lucene/Solr. In this talk we will present the reasons and benefits of the migration to Solr and an overview of how CloudSearch leverages Solr to handle millions of search requests and document updates every hour for thousands of AWS users.,,
2014,"Washington, DC",Maxim Charkov,Airbnb,,Airbnb's Search Architecture: Marketplace Matchmaking with Lucene ,Use Case,"Search on Airbnb presents an interesting set of challenges and considerations that is very different from traditional information retrieval problems. Each of the over 800,000 listings on the platform represents a unique product that only exists in one instance. Airbnb hosts, the other side of the marketplace, are active participants in the transaction process, which brings a human dimension to the search problem and requires balancing of relevance for the searchers with inferred preferences of the sellers. Airbnb's algorithms need to learn the specifics of local markets and tailor the ranking models to every possible location.In this presentation, Maxim Charkov will discuss how Airbnb engineers built a highly customized and sophisticated search system on top of core Lucene that accomplishes the goal of matching Airbnb users to an ideal listing on this new type of marketplace product.",https://www.youtube.com/watch?v=qeLekzZc3XU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=6,http://www.slideshare.net/lucidworks/airbnb-searcharchitecture-maximcharkov
2014,"Washington, DC",David Troiano,Basis Technology,,Optimizing Multilingual Search,Tutorial," Multilingual search requires the developer to address challenges that don't exist in the monolingual case. In Solr, a robust multilingual search engine requires different analysis chains for each language because each language has its own logic for tokenization, lemmatization, stemming, synonyms, and stop words.  To make multilingual search even harder, query strings are typically no longer than a handful of words, making language identification of query strings more difficult, or at worst ambiguous even to a human (""pie"" could be an English or Spanish query). We'll explore the breadth of Solr schema and configuration options available to a multilingual search application developer to balance functionality, performance, and complexity. We'll dive deep into specific experiments with a practical application.",https://www.youtube.com/watch?v=D-88Q1QbSl0&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=21,http://www.slideshare.net/lucidworks/optimizing-multilingual-search-david-troiano
2014,"Washington, DC",Anirudha Jadhav,Bloomberg,,Never Stop Exploring: Pushing the Limits of Solr,Use Case,"The goal of the presentation is to delve into the implementation of Solr, with a focus on how to optimize Solr for big data search. Solr implementations are frequently limited to 5k-7k ingest rates in similar use cases. I conducted several experiments to increase the ingest rate as well as throughput of Solr, and achieved a 5x increase in performance, or north of 25k documents per second. Typically, optimizations are limited by the available network bandwidth. I used three key metrics to benchmark the performance of my Solr implementation: time triggers, document size triggers and document count triggers. The talk will delve into how I optimized the search engine, and how my peers can coax similar performance out of Solr. This is intended to be an in-depth description of the high-frequency search implementation, with q/a with the audience. All implementations described here are based on latest SolrCloud multi-datacenter setups.   ",https://www.youtube.com/watch?v=I6Cn0exWlsQ&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=27,http://www.slideshare.net/lucidworks/never-stop-exploring-pushing-the-limits-of-solr-presented-by-anirudha-jadhav-bloomberg-lp
2014,"Washington, DC",Harry Hight,Bloomberg L.P.,,Efficient Scalable Search in a Multi-Tenant Environment ,Use Case,"Bloomberg Vault is a hosted communications archive and search solution, with over 2.5 billion documents in a 45TB Solr index. This talk will cover some of the challenges we encountered during the development of our Solr search backend, and the steps we took to overcome them, with emphasis on security and scalability. Basic security always starts with different users having access to subsets of the documents, but gets more interesting when users only have access to a subset of the data within a given document, and their search results must reflect that restriction to avoid revealing information.Scaling Solr to such extreme sizes presents some interesting challenges. We will cover some of the techniques we used to reduce hardware requirements while still maintaining fast responses times.",https://www.youtube.com/watch?v=bbbtVQCezaU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=16,http://www.slideshare.net/lucidworks/efficient-scalable-search-in-a-multi-tenant-environment-harry-hight
2014,"Washington, DC",Steven Bower,Bloomberg L.P.,,Search Analytics Component,Internals,"Search at Bloomberg is not just about text, it's about numbers, lots of numbers. In order for our clients to research, measure and drive decisions from those numbers we must provide flexible, accurate and timely analytics tools. We decided to build these tools using Solr, as Solr provides the indexing performance, filtering and faceting capabilities needed to achieve the flexibility and timeliness required by the tools. To perform the analytics required we developed an Analytics component for Solr. This talk will cover the Analytics Component that we built at Bloomberg, some use cases that drove it and then dive into features/functionality it provides.",https://www.youtube.com/watch?v=d5eGPi4KjiM&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=42,http://www.slideshare.net/lucidworks/search-analytics-component-presented-by-steven-bower-bloomberg-lp
2014,"Washington, DC",Nitin Sharma,BloomReach,,Solr Compute Cloud (Sc2)  - An Elastic Solr Infrastructure,Open Source / Industry,"Scaling Search Platforms for serving hundreds of millions of documents with low latency and high throughput  workloads at an optimized cost is an extremely hard problem. At BloomReach, we have implemented Sc2 which is an  Elastic Solr Infrastructure for Big Data Applications supporting heterogeneous workloads and hosted in the cloud. It dynamically grows/shrinks search servers to  provide Application and Pipeline level isolation, NRT Search and Indexing, Latency Guarantees, Application specific Performance Tuning. In addition to that it provides various  High Availability Features  such as Differential Realtime Streaming, Disaster Recovery, Context Aware Replication, Automatic Shard & Replica ReBalancing -- all with a zero downtime guarantee for all consumers. This  infrastructure currently serves hundreds of millions of documents in millisecond response times with a load ranging between 100K- 120K QPS(Queries Per Second).The presentation will be describing an innovate implementation (and a success story) of  scaling solr in an elastic fashion.We will be going over the architecture and also take a deep dive into how each of these components interact to make the infrastructure truly elastic, real time, robust while guaranteeing serving latency needs.",https://www.youtube.com/watch?v=1sxBiXsW6BQ&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=10,http://www.slideshare.net/lucidworks/solr-compute-cloud-an-elastic-solr-infrastructure-presented-by-nitin-sharma
2014,"Washington, DC",Wei Zhao,Box,,Content Search for Business Using Solr,Use Case,"Box uses Solr as the search engine at backend. In this talk, we will discuss how we create a search infrastructure on top of Solr to provide a fast, scalable and highly available search. We will also explore how we provide different business features by leveraging Solr. You will get a chance to look at the infrastructure of one of the biggest Solr deployments.",https://www.youtube.com/watch?v=PQ4RBCFwuVs&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=40,http://www.slideshare.net/lucidworks/content-search-for-business
2014,"Washington, DC",Gregory Chanan,Cloudera,,Secure Solr with Apache Sentry,Open Source / Industry,"Apache Solr, unlike other enterprise ""Big Data"" applications that it is increasingly deployed alongside, provides minimal security features out of the box.  This limitation makes it significantly more burdensome for organizations to deploy Solr than solutions that have built-in support for standard authentication and authorization mechanisms.   Apache Sentry is a project in the Apache Incubator designed to address these concerns.Sentry augments Solr with support for Kerberos authentication as well as collection and document-level access control.  In this talk, we'll discuss the ACL models and features of Sentry's security mechanisms.  We will also present implementation details on Sentry's integration with Solr.  Finally, we will present performance measurements in order to characterize the impact of integrating Sentry with Solr.",https://www.youtube.com/watch?v=8JN-iK0siYs&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=17,http://www.slideshare.net/lucidworks/secure-search-using-apache-sentry-to-add-authentication-and-authorization-support-to-solr-presented-by-gregory-chanan-cloudera
2014,"Washington, DC",Mark Miller ,Cloudera,,"Solr on HDFS - Past, Present, and Future.",Open Source / Industry,"Solr committer Mark Miller will discuss running Solr on the Hadoop distributed filesystem, HDFS. The presentation will include information about the history of Solr and HDFS, discuss what is in Solr today, and pontificate on improvements and benefits coming to Solr and HDFS integration in the future. There is a long history of users trying to combine Solr and HDFS, but nothing that has yet really made a large impact. First class HDFS support in Solr is beginning to change that. Come learn about Solr's HDFS support - the history, the benefits, the limitations, the future. Note: Hadoop and Solr integration is accelerating in a variety of areas, but this presentation will focus on HDFS integration.",https://www.youtube.com/watch?v=ljlARIDjxzQ&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=5,http://www.slideshare.net/lucidworks/solr-on-hdfs-final-mark-miller
2014,"Washington, DC",Romain Rigaux,Cloudera,,Interactively Search and Visualize Your Big Data,Open Source / Industry,"Open up your user base to the data! Contrary to programming and SQL, almost everybody knows how to search!This talk describes through an interactive demo based on open source Hue how users can graphically search their data in Hadoop. The underlying technical details of the application and its interaction with Apache Solr will be clarified.First, we will detail how to get started with data indexing in just a few clicks. Then the presentation will follow with several data analysis scenarios. Through a Web Browser, we will show how one can explore and visualize data for quick answers. The new search dashboard in Hue with its draggable charts and dynamic interface lets any non technical user look for documents or patterns.To sum-up, attendees of this talk will learn how to get started with interactive search visualization in their Hadoop cluster.",https://www.youtube.com/watch?v=CUsorzFoYMA&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=35,http://www.slideshare.net/lucidworks/interactively-search-and-visualize-your-data-presented-by-romain-rigaux-cloudera
2014,"Washington, DC",Don Pinto,Couchbase,,"""N1QL"" a Rich Query Language for Couchbase",Open Source / Industry,"NoSQL allows you to break free from the flat and rigid relational data model by providing semantics for navigating, constructing, or comparing rich data. In this talk, we introduce N1QL (pronounced ""Nickel""), a next generation SQL-like query language for Couchbase that is currently in developer preview. We will also walk you through a few queries of N1QL, and demonstrate how N1QL can be used in many applications including e-commerce and social gaming.",https://www.youtube.com/watch?v=xOBH7AYUrgI&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=19,http://www.slideshare.net/lucidworks/n1ql-a-rich-query-language-for-couchbase-presented-by-don-pinto-couchbase
2014,"Washington, DC",Jim Strassburg,DirectSupply,,Evolving Search Relevancy,Use Case,"Evaluating search engine results is often considered a human intelligence task. We search for something, look at search results, evaluate the results mentally, and then nudge boost values or other parameters up or down and re-evaluate. Sometimes we involve others. Selecting the best tuning parameters is as an optimization problem. A genetic algorithm (GA) is one technique that can solve this optimization problem. I present a methodology and sample implementation for modeling search parameters as individuals in a GA population and driving the fitness function off a discounted precision and recall calculation obtained from historical analytics. The same fitness function can also test the impact of one-off fixes in the search engine algorithm.",https://www.youtube.com/watch?v=RHKqcs1Gv3Q&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=14,http://www.slideshare.net/lucidworks/evolving-search-relevancy-presented-by-james-strassburg-direct-supply
2014,"Washington, DC",Shikhar Bhushan,Etsy,,Search-Time Parallelism: An Experiment,Internals," Is it possible to gain the parallelism benefit of sharding your data into multiple indexes, without actually sharding? Isn't your Lucene index already composed of shards i.e. segments? This talk will present an experiment in parallelizing Lucene's guts: the collection protocol. An express goal was to try to do this in a lock-free manner using divide-and-conquer.Changes to the Collector API were necessary, such as orienting it to work at the level of child ""leaf""-collectors so that segment-level state could be accumulated in parallel. I will present technical details that were learned along the way, such as how Lucene's TopDocs collectors are implemented using priority queues and custom comparators.Onto the parallelizability of collectors qne how some collectors like hit counting are embarrassingly parallelizable, how some like DocSet collection were a delightful challenge, and others where the space-time tradeoffs need more consideration.Performance testing results, which currently span from worse to exciting, will be discussed.",https://www.youtube.com/watch?v=bAZJmMUbn20&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=38,http://www.slideshare.net/lucidworks/searchtime-parallelism-presented-by-shikhar-bhushan-etsy-41862845
2014,"Washington, DC",Liang Shen,European Bioinformatics Institute,,Edanz Journal Selector: Case Study: a Prototype based on Solr/Nutch/Hadoop,Use Case,"The TF-IDF (term frequency, inverse document frequency) based scoring mechanism in Lucene/Solr can be used as a powerful recommendation engine. Rather than searching, this session will introduce a peculiar use-case, Edanz Journal Selector, a tool for scholars to find out the right journals to publish their papers. I will show how did we built this system with Solr, Nutch, Hadoop and other open source projects. I will also demonstrate our global deployment strategy for providing services to different locations on Amazon web serves. ",https://www.youtube.com/watch?v=VNPpyERGsVA&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=4,http://www.slideshare.net/lucidworks/edanz-journal-selector-presented-by-liang-shen-european-bioinformatics-institute
2014,"Washington, DC",Christian Kohlschutter,Evernote,,Search Architecture at Evernote: Not Your Typical Big Data Problem,Internals,"With over 100 Million users from around the globe, Evernote has set out to redefine the meaning of productivity for modern busy people. We want Evernote to become your workspace; the place where you do all of the everyday things that keep your life moving forward.This talk will cover Evernote's search architecture that runs more than 200,000 user-specific Lucene indexes per server, and the challenges that emerge from this unique setting. In the past two years, we have successfully turned a solid but outdated Lucene 2.9 installation into an environment that allows specific search engines and experimental configurations to be run for each individual user. This enabled us to migrate our entire user base to Lucene 4 with almost no downtime, and to deploy a custom directory-level compression, saving us almost a petabyte of index-related disk IO per week.",https://www.youtube.com/watch?v=drOmahIie6c&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=25,http://www.slideshare.net/lucidworks/search-architechture-at-evernote-presented-by-christian-kohlschtter-evernote
2014,"Washington, DC",Jacob Graves,Getty Images,,Managed Search,Use Case,"This talk will cover the creation of a Search Administration Workbench application leveraging distributed Solr index. Search is at the core of many modern commercial applications, as the scoring algorithms and shuffles used when returning data to users has a direct impact on sales. This makes Search an area of importance to business users, but the technical complexity of Search often creates a barrier of understanding between the technology and the business. An administration workbench is an application that seeks to bridge this gap with simplified algorithm and shuffle controls, immediate results display, scale reporting and the ability to push new configuration settings to the customers and measure their impact.In this presentation Jacob will discuss how Getty Images built the administration workbench on top of Solr taking advantage of Solr's custom query function plugins and a new custom collector component.",https://www.youtube.com/watch?v=0caFZs7MuhU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=15,http://www.slideshare.net/lucidworks/managed-search-presented-by-jacob-graves-getty-images
2014,"Washington, DC",Mikhail Khludnev,Grid Dynamics,,Approaching Join Index,Internals," Lucene works great with independent text documents, but real life problems often require to handle relations between documents. Aside from several workarounds, like term encodings, field collapsing or term positions, we have two mainstream approaches to handle document relations: join and block-join. Both have their downsides. Join lacks performance, while block-join makes is really expensive to handle index updates, since it requires to wipe a whole block of related documents. This session presents an attempt to apply join index, borrowed from RDBMS world, for addressing drawbacks of the both join approaches currently present in Lucene. We will look into the idea per se, possible implementation approaches, and review the benchmarking results.",https://www.youtube.com/watch?v=Il7wdhbA2kU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=8,http://www.slideshare.net/lucidworks/approaching-join-index-presented-by-mikhail-khludnev-grid-dynamics
2014,"Washington, DC",Oleg Savrasov,Grid Dynamics,,Faceting with Lucene BlockJoinQuery,Internals,"Lucene originally was designed to work with flat documents composed from fields and terms. This model is not very friendly for hierarchical document structures, which are very important in many business areas, such as retail, where product-sku parent/child relationships are very common. To address this limitation, high performant BlockJoin solution was introduced in Solr 4.5. It requires to index related documents as separate blocks, and allows using special BlockJoinQuery for search and filtering with respect to document relations. At the same time, the problem of calculating facets on a set of hierarchical documents, such as product-sku structures, has not been resolved yet, see SOLR-5743 - Faceting with BlockJoin support.This talk is about a proposed Solr component intended to calculate facets over search results returned by BlockJoinQuery. Facet counts are supposed to be collapsed and equal to amount of parent documents with children that have correspondent field value. So it's quite close to executing aggregate database query likeSELECT count(*) FROM child JOIN parent ON child.parent_id=parent.idWHERE child.<fieldName>=<facetValue> GROUP BY parent.id;We'll consider component design, performance measurements and the ways for further improvements.  ",https://www.youtube.com/watch?v=Su5SHc_uJw8&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=11,http://www.slideshare.net/lucidworks/faceting-with-lucene-block-join-query-oleg-savrasov
2014,"Washington, DC",Ravi Mynampaty,Harvard Business School,,Building a Solr-Driven Web Portal,Use Case,"This presentation is a case study of how we built a Solr-driven search-based portal for Harvard Business School (HBS) Alumni, and buoyed by this successful implementation of Solr, how we are expanding its use to other areas of the Enterprise.  You will hear about how choosing the Solr approach saved us a ton of custom development, and enabled us to offer end-users features such as personalization, faceted search and navigation of various types of content (e.g., people, events, alumni stories), autocomplete, and a geolocation mapping UI for navigating the people directory.  In addition to a demo of the end-user UI, we will outline technical implementation detailsâ€_these will include how we modeled the content in the database to work with Solr, developed a Ã±search wrapperÃ® to handle access control by brokering the requests/responses between the UI layer and Solr, and developed a custom Java loader to import content from our RDBMS into Solr.  In short, this talk will describe the path we took in adopting Solr, speed bumps and potholes we hit along the way, where we are currently, and what the future roadmap looks like for using Solr in the HBS Enterprise.  ",https://www.youtube.com/watch?v=-4Fxrj_R2dU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=3,http://www.slideshare.net/lucidworks/building-a-solr-driven-web-portal-ravi-mynampaty-katia-muser
2014,"Washington, DC",Yonik Seeley,Heliosearch,,Native Code and Off-Heap Data Structures for Solr,Internals,"Off-heap data structures and native code performance improvements for Apache Solr are being developed as part of the Heliosearch project. This presentation will cover the reasons behind these features, implementation details, and performance impacts.  Recently developed features will also be covered.",https://www.youtube.com/watch?v=dDywZDQJQ3o&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=39,http://www.slideshare.net/lucidworks/native-code-off-heap-data-structures-for-solr-yonik-seeley
2014,"Washington, DC",Diego Buthay,LinkedIn,,The LinkedIn Search Architecture,Use Case,"LinkedIn's corpus is a richly structured professional graph comprised of 300M+ people, 3M+ companies, 2M+ groups, and 1.5M+ publishers. Members perform billions of searches, and each of those searches is highly personalized based on the searcher's identity and relationships with other professional entities in LinkedIn's economic graph. And all this data is in constant flux as LinkedIn adds more than 2 members every second in over 200 countries (2/3 of whom are outside the United States).As a result, we've built a system quite different from those used for other search applications. In this talk, we will discuss some of the unique systems challenges we've faced as we deliver highly personalized search over semi-structured data at massive scale.",https://www.youtube.com/watch?v=8O7cF75intk&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=43,http://www.slideshare.net/lucidworks/galene-linkedins-search-architecture-presented-by-diego-buthay-sriram-sankar-linkedin
2014,"Washington, DC",Darren Spehr,"MapQuest, Inc.",,High Performance Solr and JVM Tuning Techniques Used in MapQuest's Autocomplete Service,Tutorial,"As with any service of its kind, MapQuest's autocompletion service has very strict performance requirements.  In our case, we cap all queries at 120 milliseconds.  For small collections, simple queries or low-demand services this may be easy to reach with little extra work.  However our service searches across 100 billion points of data organized across 5 vastly different collections and has a peak query volume that can exceed 9000 requests per minute.  Taken together it means we had to independently tune each Solr instance for peak efficiency.  In this presentation I will discuss the aspects of design that we found affected our perforance the most.  This includes data organization, sharding strategies, query construction, threading, and caching.  I will also cover our approach to the art and science of tuning the JVM, the tools we used, and the methods we found that helped us the most.  Finally I will discuss our approach to capacity planning and our experience scaling our collections.",https://www.youtube.com/watch?v=8JADOLMazs4&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=23,http://www.slideshare.net/lucidworks/high-performance-solr-and-jvm-tuning-strategies-used-for-map-quests-search-ahead-darren-spehr
2014,"Washington, DC",Joe Blue,MapR,,Search Engines for Machine Learning,Use Case,"Search engines can be used for a variety of high-value machine learning applications. Practical machine learning involves more than just machine learning itself. It is also necessary to be able to deploy, monitor, manage, and understand the operation of any advanced analytics application. Recent developments in machine learning allow search engines such as Lucene and Solr to be used to deploy such advanced analytics systems. This has many practical benefits because search engines based on Lucene collectively have nearly a mega-year of run-time and are thus correspondingly stable.Joe will describe how a surprisingly small amount of code can be used to deploy a recommendation engine on top of Solr. All required code is available as open source and after this talk, most implementors will have enough information to implement a production quality recommendation engine in a few days of effort. He will also have additional handouts at the talk to assist developers.",https://www.youtube.com/watch?v=FEtjBRkO5_4&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=13,http://www.slideshare.net/lucidworks/search-engines-for-machine-learning-presented-by-joe-blue-mapr
2014,"Washington, DC",David Smiley,,,The Latest in Spatial/Temporal Search,Internals,"This talk is about the latest developments in spatial search on Lucene/Solr.  The biggest addition is accurate polygonal search which works by storing the vector geometry in addition to a grid based index. The search uses both for speed and accuracy. In addition to this, the grid-based index has improved performance. Over the past year, five mentored students contributed to various areas of spatial search to include benchmarking, geodetic shapes (surface of a sphere), and an improved grid. I'll quickly review their contributions. Lucene/Solr now has a date duration field type, and it's internally based on Lucene's spatial module using a new date oriented prefix tree. Not only can you index and search multiple time durations per document, and use different relation predicates, but you can also facet across them too, similar to Solr's date range faceting. The faceting is designed to scale well using an approach similar to facet.method=enum, which should be faster and use less RAM than conventional date range faceting.",https://www.youtube.com/watch?v=D_DLMyk7hMI&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=22,http://www.slideshare.net/lucidworks/the-latest-in-spatialtemporal-search-presented-by-david-smiley
2014,"Washington, DC",Rahul Jain,,,Building a Large scale SEO/SEM Application with Apache Solr,Use Case,"Search engine optimization (SEO) is the process of affecting the visibility of a website or a web page in a search engine's ""natural"" or un-paid (""organic"") search results while other side Search engine marketing (SEM) is a form of Internet marketing that involves the promotion of websites by increasing their visibility in search engine results pages (SERPs) through optimization and advertising. We are working on building a SEO/SEM application where an end user search for a ""keyword"" or a ""domain"" and gets all the insights about these including Search engine ranking, CPC/CPM, search volume, No. of Ads, competitors details etc. in a couple of seconds. To have this intelligence, we get huge web data from various sources and after intensive processing it is as much as 40 billion records/month in MySQL database with 4.6 TB compressed index data in Apache Solr.Due to large volume, we faced several challenges while improving indexing performance, search latency and scaling the overall system. In this session, I will talk about our several design approaches to import data faster from MySQL, tricks & techniques to improve the indexing performance, Distributed Search, DocValues(life saver), Redis and the overall system architecture.",https://www.youtube.com/watch?v=9ug9dTrcjDU&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=31,http://www.slideshare.net/lucidworks/building-a-large-scale-seo-sem-application-with-apache-solr-rahul-jain
2014,"Washington, DC",Ramzi Alqrainy,Opensooq,,Arabic Content with Solr,Use Case,"Arabic language poses several challenges faced by the Natural Language Processing (NLP), largely due to the fact that Arabic language, unlike European languages, has a very rich and sophisticated morphological system. This talk will cover some of the challenges and how to solve them with Solr and will also present the challenges that were handled by Opensooq as a real case in the Middle East . ",https://www.youtube.com/watch?v=K6zehH_FOSk&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=33,http://www.slideshare.net/lucidworks/arabic-content-with-apache-solr-presented-by-ramzi-alqrainy
2014,"Washington, DC",Dibyendu Bhattacharya,Pearson North America,,Near Real Time Indexing Kafka Messages into Apache Blur,Open Source / Industry,"This session talks about how we designed fault tolerant Kafka Consumer to index Kafka messages into Apache Blur. Apache Blur is Hadoop based search platform built on top of Lucene. Recently we evaluated Apache Blur and this talk will cover some interesting learning about indexing real time streams into Blur and how it used blur queuing mechanism for achieving the same. This session will also cover some design and approach to implement a fault tolerant Kafka Consumer to index Kafka Streams into Blur using latest Blur queuing mechanism. Kafka-Blur consumer can detect number of Partitions for a Kafka Topic and spawn that many threads to index messages using Blur real time indexing feature. It uses Zookeeper for storing the latest offset of the indexed messages, which will help to recover in case of failure . The indexing logic is pluggable and one can define their own indexing logic for Kafka messages to target Blur table.",https://www.youtube.com/watch?v=n7lfYhJgtJo&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=20,http://www.slideshare.net/lucidworks/near-real-time-indexing-kafka-messages-into-apache-blur-presented-by-dibyendu-bhattacharya-pearson-north-america
2014,"Washington, DC",Paul Nelson,Search Technologies,,"SolrCloud, in the Cloud, for NARA's Billion+ Document Archive",Use Case,"The National Archives and Records Administration (NARA) is the official records keeper of the United States Government. It maintains vast archives of government records and documents of historical or legal significance. This presentation will focus on the architecture and development of NARA's ""Online Public Access"" (OPA) initiative, a public search interface for browsing both catalog information and on-line content, which is being completely rebuilt using SolrCloud, and hosted in the Cloud. Stand-out aspects of the architecture include:  1) Content processing for a wide range of content types, 2) Handling and searching over social media content (tags, comments, transcriptions, translations), 3) Scalability to billions of records, and 4) Metadata sensitive search features unique to large publishers and archives.",,
2014,"Washington, DC",Radu Gheorghe,"Sematext Group, Inc.",,Tuning Solr for Logs,Tutorial,"Performance tuning is always nice for keeping your applications snappy and your costs down. This is especially the case for logs, social media and other stream-like data, that can easily grow into terabyte territory. While you can always use SolrCloud to scale out of performance issues, this talk is about optimizing. First, we'll talk about Solr settings by answering the following questions:- How often should you commit and merge?- How can you have one collection per day/month/year/etc?- What are the performance trade-offs for these options?Then, we'll turn to hardware. We know SSDs are fast, especially on cold-cache searches, but are they worth the price? We'll give you some numbers and let you decide what's best for your use-case.The last part is about optimizing the infrastructure pushing logs to Solr. We'll talk about tuning Apache Flume for handling large flows of logs and about overall design options that also apply to other shippers, like Logstash. As always, there are trade-offs, and we'll discuss the pros and cons of each option.",https://www.youtube.com/watch?v=4L1DjY90Whk&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=44,http://www.slideshare.net/lucidworks/tuning-solr-for-logs-presented-by-radu-gheorghe
2014,"Washington, DC",Rafal Kuc,"Sematext Group, Inc.",,Solr Anti-Patterns,Tutorial,"Working as a consultant, software engineer and helping people in various ways, Rafa_ has seen multiple patterns in how Solr is used and how it should be used. We usually say what should be done, but we don't talk and point out what shouldn't be done. This talk will point out common mistakes and roads that should be avoided at all costs. This session will not only to show the bad patterns, but also show the differences before and after. The talk is divided into three major sections:General configuration pitfalls that people are used to making. We will discuss different use cases showing the proper path that one should take2.) We will focus on data modeling and what to avoid when making your data indexable. Again, we will see real life use cases followed by the guidance around how to handle them properly3.) Finally, we will talk about queries and all the juicy mistakes made when it comes to searching for indexed dataEach shown use case will be illustrated by the before and after analysis - we will see the metrics changes, so the talk will not only bring pure facts, but hopefully know-how worth remembering. ",https://www.youtube.com/watch?v=H53w9cXVTAM&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=30,http://www.slideshare.net/lucidworks/solr-antipatterns-presented-by-rafa-kuc
2014,"Washington, DC",Chris Becker,Shutterstock,,Searching 35 Million Images by Color Using Solr,Use Case,"This talk will cover some of the methods we've used for building color search applications at Shutterstock using Solr to search 40 million images.  A couple of these applications can be found in Shutterstock Labs - notably Spectrum and Palette.  I'll go over the steps for extracting color data from images and indexing them into Solr, as well as looking at some ways to query color data in your Solr index.  We'll cover some issues such as what does relevance mean when you're searching for colors rather than text, and how you can achieve various effects by ranking on different visual attributes.  ",https://www.youtube.com/watch?v=WjnLhtwp678&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=26,http://www.slideshare.net/lucidworks/searching-images-by-color-presented-by-chris-becker-shutterstock
2014,"Washington, DC",Renaud Delbru ,Siren Solutions,,Searching and Querying Knowledge Graphs with Solr/SIREn: a Reference Architecture,Use Case,"Knowledge Graphs have recently gained press coverage as information giants like Google, Facebook, Yahoo and Microsoft, announced having deployed Knowledge Graphs at the core of their search and data management capabilities. Very richly structured datasets like Ã±FreebaseÃ® or Ã±DBPediaÃ® can be said to be examples of these. In this talk we discuss a reference architecture for high performance structured querying and search on knowledge graphs. While graph databases, e.g., Triplestores or Graph Stores, have a role in this scenario, it is via Solr along with its schemaless structured search plugin SIREn that it is possible to deliver fast and accurate entity search with rich structured querying. During the presentation we will discuss an end to end example case study, a tourism social data use case. We will cover extraction, graph databases, SPARQL, JSON-LD and the role of Solr/SIREn both as search and as high speed structured query component. The audience will leave this session with an understanding of the Knowledge Graph idea and how graph databases, SPARQL, JSON-LD and Solr/SIREn can be combined together to implement high performance real world applications on rich and diverse structured datasets.",https://www.youtube.com/watch?v=rtXRJbyI1lc&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=34,http://www.slideshare.net/lucidworks/searching-and-querying-knowledge-graphs-with-solrsiren-a-reference-architecture
2014,"Washington, DC",Neeraj Jain,Stubhub,, De-Duplication Using Solr,Use Case,"Stubhub handles large number of events and related documents. Use of Solr within Stubhub has grown from search for events/tickets to content ingestion. One of the major challenges that are faced in content ingestion systems is to detect and remove duplicates without compromising on quality and performance.We present a solution that involves spatial searching, custom update handler, custom geodist function etc, to solve the de-duplication problem.In this talk, we'll present design and implementation details of the custom modules and APIs and discuss some of the challenges that we faced and how we overcame them.We'll also present the comparison analysis between old and the new system used for de-duplication.",https://www.youtube.com/watch?v=lWVISTbigOM&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=9,http://www.slideshare.net/lucidworks/deduplication-using-solr-presented-by-neeraj-jain-stub
2014,"Washington, DC",Raja Ramachandran,Target,,The Journey of Implementing Solr at Target,Use Case,"Sending Solr into action on a high volume, high profile website within a large corporation presents several challenges, and not all of them are technical. This will be an open discussion and overview of the journey at Target to date. We'll cover some of the wins, losses and ties that we've had while implementing Solr at Target as a replacement for a legacy enterprise search platform. In some cases the solutions were basic, while others required a little more creativity. We'll cover both to paint the whole picture.",https://www.youtube.com/watch?v=hxAnFdFF33A&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=32,http://www.slideshare.net/lucidworks/journey-of-implementing-solr-at-target-presented-by-raja-ramachandran-target
2014,"Washington, DC",Damiano Braga,Trulia,,Thoth: Real-time Solr Monitor and Search Analysis Engine,Use Case,"Managing a large and diversified Solr search infrastructure can be challenging and there is still a lack of good tools that can help monitor the entire system and help the scaling process. This session will cover Thoth: an open source real-time Solr monitor and search analysis engine that we wrote and currently use at Trulia. We will talk about how Thoth was designed, why we chose Solr to analyze Solr and the challenges that we encountered while building and scaling the system. Then, we will talk about some Thoth useful features like integration with Apache ActiveMQ and Nagios for real-time paging, generation of reports on query volume, latency, time period comparisons and the Thoth dashboard. Following that, we will summarize our application of machine learning algorithms and its results to the process of query analysis and pattern recognition.  Then we will talk about the future directions of Thoth, opportunities to expand the project with new plug-ins and integration with Solr Cloud.",https://www.youtube.com/watch?v=YFYj-SplaII&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=24,http://www.slideshare.net/lucidworks/thoth-realtime-solr-monitor-and-search-analysis-engine-41966720
2014,"Washington, DC",Michael Busch,Twitter,,Real-time search at Twitter,Use Case,"Twitter's search engine serves billions of queries per day from different Lucene indexes, while appending more than hundreds of millions of tweets per day in real time. This session will give an overview of Twitter's search architecture and recent changes and improvements that have been made. It will focus on the usage of Lucene and the modifications that have been made to it to support Twitter's unique performance requirements.",https://www.youtube.com/watch?v=KUmFJc3fFuM&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=7,http://www.slideshare.net/lucidworks/search-at-twitter-presented-by-michael-busch-twitter
2014,"Washington, DC",Kai Chan,UCLA,,"Reading Metadata between the Lines: Searching for Stories, People, Places and More in Television News",Use Case,"UCLA's NewsScape has over 200,000 hours of television news from the United States and Europe. In the last two years, the project has generated a large set of ""metadata"": story segment boundaries, story types and topics, name entities, on-screen text, image labels, etc. Including them in searches opens new opportunities for research, understanding, and visualization, and helps answer questions such as ""Who were interviewed on which shows about the Ukraine crisis in May 2014"" and ""What text or image is shown on the screen as a story is being reported"". However, metadata search poses significant challenges, because the search engine needs to consider not only the content, but also its position and time relative to other metadata instances, whether search terms are found in the same or different metadata instances, etc. We will describe how we have implemented metadata search with Lucene/Solr's block join and custom query types, as well as the collection's position-time data. We will describe our work on using time as the distance unit for proximity search and filtering search results by metadata boundaries. We will also describe our metadata-aware, multi-field implementation of auto-suggest. ",https://www.youtube.com/watch?v=Hxq3xrBRuR8&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=12,http://www.slideshare.net/lucidworks/reading-metadata-between-the-lines-searching-for-stories-people-places-and-more-presented-by-kai-chan-ucla
2014,"Washington, DC",Alexandre Rafalovitch,United Nations,,Solr vs. ElasticSearch - Case by Case,Open Source / Industry,"Comparisons between Solr and ElasticSearch are common and popular. However, they focus on the feature checklists and are very shallow. This talk will look at the real search use-cases (searching multiple fields, dynamic fields, data import, nested documents, etc) and see how the solutions are represented in Solr's and ElasticSearch's paradigms. Some usability aspects will also be discussed (such as minimal configuration, dynamic field types, JSON handling).Finally, the talk will touch on Solr being subjected to an innovator's dilemma and possible ways to benefit, rather than suffer from it.",https://www.youtube.com/watch?v=S1Md3LDJPLs&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=2,http://www.slideshare.net/lucidworks/solr-vs-elasticsearc-a-case-by-case-presented-by-alexandre-rafalovitch-un
2014,"Washington, DC",SaÂ¥d Radhouani,Yellow Pages Group,,Anatomy of Relevance: From Data to Action,Tutorial,"Relevance denotes how well a search result satisfies the user information need. In addition to the search engine components (i.e., indexer and query parser), there are many other components that impact relevance. e.g., user understanding , data optimization, domain knowledge, etc. Improving relevance remains the main and most challenging goal of each Search Engine. Indeed, relevance can be subjective, therefore  hard to measure and to improve. In this talk, I'll demystify the concept of relevance by defining its main components. For each component, I will present the technology enablers, the data and processes that are required in order to measure and improve relevance. In the is talk you will learn how to provide a relevant user experience and track it over time.",https://www.youtube.com/watch?v=3RRC7YxEwxg&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=36,http://www.slideshare.net/lucidworks/anatomy-of-relevance-from-data-to-action-presented-by-sad-radhouani-yellow
2014,"Washington, DC",Alessandro Benedetti,Zaizi,,Multi-language Content Discovery Through Entity Driven Search,Use Case,"This talk is about the description of the implementation of a Semantic Search Engine based on Solr. Meaningfully structuring content is critical, Natural Language Processing and Semantic Enrichment is becoming increasingly important to improve the quality of Solr search results. Our solution is based on three advanced features: 1.) Entity-oriented search - Searching not by keyword, but by entities (concepts in a certain domain), 2.) Knowledge graphs - Leveraging relationships amongst entities: Linked Data datasets (Freebase, DbPedia, Custom Æ’) and 3.) Search assistance - Autocomplete and Spellchecking are now common features, but using semantic data makes it possible to offer smarter features, driving the users to build queries in a natural way.  The approach includes unstructured data processing mechanisms integrated with Solr to automatically index semantic and multi-language information. Smart Autocomplete will complete users' query with entity names and properties from the domain knowledge graph. As the user types, the system will propose a set of named entities and/or a set of entity types across different languages. As the user accepts a suggestion, the system will dynamically adapt following suggestions and return relevant documents. Semantic More Like This will find similar documents to a seed one, based on the underlying knowledge in the documents, instead of tokens.  ",https://www.youtube.com/watch?v=eeIJh8xirOk&list=PLU6n9Voqu_1FM8nmVwiWWDRtsEjlPqhgP&index=1,http://www.slideshare.net/lucidworks/multilanguage-content-discovery-through-entity-driven-search-alessandro-benedetti
2014,"Washington, DC",Dragan  Milosevic,Zanox,,Better Faceting: Data Cleaning with Hadoop,Open Source / Industry,"While adding facets to search results has never been easier, enhancing user experience usually requires application of sophisticated data cleaning techniques. They are especially important  for systems that collect documents from thousands of different sources and extensively use available attributes to build various types of facets. As every data-source might use its own naming conventions, original attribute values that represent same entities could be different, which limits their usability for building facets. The initial challenge to be solved is designing a similarity function that both efficiently computes direct string distances between attribute values and also learns to deduce the represented semantics in order to reduce the amount of false positives. Naive quadratic-time running algorithm that exhaustively applies the designed similarity function to each and every pair of attribute values is not usable even for cleaning collections with a modest cardinality. It is therefore transformed into an efficient linear-time running algorithm by first clustering Soundex codes of attribute values into canopies and then comparing only values that belong to the same canopy. The final optimization is Hadoop application to parallelize and further speed-up designed data-cleaning algorithm, as well as the compact representation of obtained transformation rules by using Finite State Transducers.",,